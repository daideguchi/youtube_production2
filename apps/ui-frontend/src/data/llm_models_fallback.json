[
  {
    "id": "qwen3-235b",
    "label": "Qwen3-235B A22B (MoE)",
    "provider": "OpenRouter",
    "model_id": "qwen/qwen3-235b-a22b:free",
    "iq": 120,
    "knowledge_metric": { "name": "MMLU-Redux", "value": 87.4, "source": "https://www.reddit.com/r/LocalLLaMA/comments/1kh6kh3/qwen3_mmlupro_computer_science_llm_benchmark/" },
    "specialist_metric": { "name": "LiveCodeBench v5", "value": 70.7, "source": "https://openlaboratory.ai/models/qwen3-235b-a22b" },
    "notes": "MoE 235B/22B アクティブ。AIME'24 85.7 など推論寄りセットで SOTA 級。長文 reasoning → coding の両刀向け。",
    "last_updated": "2025-11-17T02:40:00+09:00"
  },
  {
    "id": "qwen3-30b",
    "label": "Qwen3-30B A3B",
    "provider": "OpenRouter",
    "model_id": "qwen/qwen3-30b-a3b:free",
    "iq": 115,
    "knowledge_metric": { "name": "MMLU", "value": 81.38, "source": "https://openlaboratory.ai/models/qwen3-30b-a3b" },
    "specialist_metric": { "name": "LiveCodeBench v6", "value": 66.0, "source": "https://skywork.ai/blog/models/yoyo-ai-qwen3-30b-a3b-yoyo-v5-free-chat-online-skywork-ai/" },
    "notes": "MoE 30B/3B アクティブで高速。agent / tool タスクでも QwQ-32B 相当。",
    "last_updated": "2025-11-17T02:40:00+09:00"
  },
  {
    "id": "qwen3-14b",
    "label": "Qwen3-14B Instruct",
    "provider": "OpenRouter",
    "model_id": "qwen/qwen3-14b:free",
    "iq": 112,
    "knowledge_metric": { "name": "MMLU", "value": 81.05, "source": "https://openlaboratory.ai/models/qwen3-14b" },
    "specialist_metric": { "name": "GSM8K", "value": 92.49, "source": "https://openlaboratory.ai/models/qwen3-14b" },
    "notes": "dense 14B でも多言語/数理が強く、長文 TTS リライトでも破綻しない安定感。",
    "last_updated": "2025-11-17T02:40:00+09:00"
  },
  {
    "id": "qwen3-4b",
    "label": "Qwen3-4B Instruct",
    "provider": "OpenRouter",
    "model_id": "qwen/qwen3-4b:free",
    "iq": 106,
    "knowledge_metric": { "name": "MMLU-Redux", "value": 83.7, "source": "https://openlaboratory.ai/models/qwen3-4b" },
    "specialist_metric": { "name": "MATH-500", "value": 97.0, "source": "https://openlaboratory.ai/models/qwen3-4b" },
    "notes": "4B でも Qwen2.5-72B 級。グラフィックレスの省メモリ推論やバックアップ用途に最適。",
    "last_updated": "2025-11-17T02:40:00+09:00"
  },
  {
    "id": "qwen3-coder",
    "label": "Qwen3-Coder 480B A35B",
    "provider": "OpenRouter",
    "model_id": "qwen/qwen3-coder:free",
    "iq": 118,
    "knowledge_metric": { "name": "SWE-Bench Verified", "value": 67.0, "source": "https://www.digitalocean.com/community/tutorials/qwen3-coder-agentic-coding-model" },
    "specialist_metric": { "name": "LiveCodeBench v5", "value": 70.6, "source": "https://binaryverseai.com/qwen3-coder-review/" },
    "notes": "Agentic coding 向け。SWE-Bench 69.6% (500 turn) に届くが、リクエストコストは無料枠内。",
    "last_updated": "2025-11-17T02:40:00+09:00"
  },
  {
    "id": "qwen2.5-72b",
    "label": "Qwen2.5-72B Instruct",
    "provider": "OpenRouter",
    "model_id": "qwen/qwen-2.5-72b-instruct:free",
    "iq": 111,
    "knowledge_metric": { "name": "MMLU", "value": 86.1, "source": "https://www.alibabacloud.com/blog/601786" },
    "specialist_metric": { "name": "MBPP", "value": 88.2, "source": "https://www.alibabacloud.com/blog/601786" },
    "notes": "従来の安定枠。Qwen3 429 時の保険として残す。",
    "last_updated": "2025-11-17T02:40:00+09:00"
  },
  {
    "id": "qwen2.5-32b",
    "label": "Qwen2.5-32B Instruct",
    "provider": "OpenRouter",
    "model_id": "qwen/qwen-2.5-coder-32b-instruct:free",
    "iq": 108,
    "knowledge_metric": { "name": "MMLU-Redux", "value": 83.9, "source": "https://www.alibabacloud.com/blog/601786" },
    "specialist_metric": { "name": "LiveCodeBench", "value": 51.2, "source": "https://www.alibabacloud.com/blog/601786" },
    "notes": "32B 帯で小型汎用モデル相当の扱いやすさ。",
    "last_updated": "2025-11-17T02:40:00+09:00"
  },
  {
    "id": "llama-3.3-70b",
    "label": "Llama 3.3 70B Instruct",
    "provider": "OpenRouter",
    "model_id": "meta-llama/llama-3.3-70b-instruct:free",
    "iq": 111,
    "knowledge_metric": { "name": "MMLU Chat", "value": 86.0, "source": "https://privatellm.app/blog/llama-3-3-70b-available-locally-private-llm-macos" },
    "specialist_metric": { "name": "HumanEval", "value": 88.4, "source": "https://privatellm.app/blog/llama-3-3-70b-available-locally-private-llm-macos" },
    "notes": "英語編集や多言語 Q&A のバックアップ。",
    "last_updated": "2025-11-17T02:40:00+09:00"
  },
  {
    "id": "mistral-small-3.2-24b",
    "label": "Mistral Small 3.2 24B",
    "provider": "OpenRouter",
    "model_id": "mistralai/mistral-small-3.2-24b-instruct:free",
    "iq": 103,
    "knowledge_metric": { "name": "MMLU", "value": 80.5, "source": "https://topmostads.com/mistral-small-3-2-update-analysis/" },
    "specialist_metric": { "name": "HumanEval+", "value": 92.9, "source": "https://topmostads.com/mistral-small-3-2-update-analysis/" },
    "notes": "Apache2.0 / 24B。英語長文かつ高速レスが必要な場合に。",
    "last_updated": "2025-11-17T02:40:00+09:00"
  },
  {
    "id": "deepseek-v3.1",
    "label": "DeepSeek-V3.1",
    "provider": "OpenRouter",
    "model_id": "deepseek/deepseek-chat-v3.1:free",
    "iq": 98,
    "knowledge_metric": { "name": "MMLU-Pro", "value": 81.2, "source": "https://api-docs.deepseek.com/updates" },
    "specialist_metric": { "name": "LiveCodeBench", "value": 49.2, "source": "https://api-docs.deepseek.com/updates" },
    "notes": "推論系 Upstream 429 多発なので冷却枠だが、レスポンス品質は高い。",
    "last_updated": "2025-11-17T02:40:00+09:00"
  },
  {
    "id": "glm-4.5-air",
    "label": "GLM-4.5 Air",
    "provider": "OpenRouter",
    "model_id": "z-ai/glm-4.5-air:free",
    "iq": 106,
    "knowledge_metric": { "name": "MMLU-Pro", "value": 84.6, "source": "https://z.ai/blog/glm-4.5" },
    "specialist_metric": { "name": "LiveCodeBench", "value": 72.9, "source": "https://z.ai/blog/glm-4.5" },
    "notes": "Chutes プロバイダ経由の無料枠。論理系の fallback。",
    "last_updated": "2025-11-17T02:40:00+09:00"
  }
]
