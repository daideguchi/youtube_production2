#!/usr/bin/env python3
"""
Extract 4 chapter titles from SRT file using Gemini LLM analysis.
"""
import os
import sys
import json
import re
from pathlib import Path
from typing import List, Dict


def parse_srt(srt_path: Path) -> List[Dict]:
    """Parse SRT and return segments with timing."""
    content = srt_path.read_text(encoding='utf-8').lstrip('\ufeff')
    pattern = r'(\d+)\n(\d{2}:\d{2}:\d{2},\d{3}) --> (\d{2}:\d{2}:\d{2},\d{3})\n(.*?)(?=\n\n|\n\d+\n|\Z)'
    matches = re.findall(pattern, content, re.DOTALL)

    def time_to_sec(t):
        h, m, s_ms = t.split(':')
        s, ms = s_ms.split(',')
        return int(h) * 3600 + int(m) * 60 + int(s) + int(ms) / 1000

    return [{
        'index': int(m[0]),
        'start_sec': time_to_sec(m[1]),
        'end_sec': time_to_sec(m[2]),
        'text': m[3].strip().replace('\n', ' ')
    } for m in matches]


def analyze_chapters(transcript: str, total_duration: float) -> List[Dict]:
    """Use Gemini to generate 4 chapter titles."""
    import google.generativeai as genai

    api_key = os.getenv('GEMINI_API_KEY')
    if not api_key:
        raise ValueError("GEMINI_API_KEY not set")

    genai.configure(api_key=api_key)
    model = genai.GenerativeModel('gemini-2.5-flash')

    prompt = f"""ä»¥ä¸‹ã¯ã€Œäººç”Ÿã®é“æ¨™ã€ã‚·ãƒªãƒ¼ã‚ºã®å°æœ¬å…¨æ–‡ï¼ˆç·æ™‚é–“: {total_duration:.1f}ç§’ï¼‰ã§ã™ã€‚

ã€ã‚¿ã‚¹ã‚¯ã€‘
ã“ã®å†…å®¹ã‚’æ™‚ç³»åˆ—ã§4ã¤ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«åˆ†å‰²ã—ã€å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«ç°¡æ½”ã§ã‚ã‹ã‚Šã‚„ã™ã„ã‚¿ã‚¤ãƒˆãƒ«ã‚’ã¤ã‘ã¦ãã ã•ã„ã€‚

ã€è¦ä»¶ã€‘
1. ã‚¿ã‚¤ãƒˆãƒ«å½¢å¼: ã€Œâ‘ ã€œã€œã€ã€Œâ‘¡ã€œã€œã€ã€Œâ‘¢ã€œã€œã€ã€Œâ‘£ã€œã€œã€
2. é•·ã•: å„15ã€œ30æ–‡å­—ï¼ˆCapCutå¸¯ãƒ¬ã‚¤ãƒ¤ãƒ¼ã«è¡¨ç¤ºï¼‰
3. å†…å®¹: è¦–è´è€…ãŒãã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ä½•ã‚’å­¦ã¶ã‹ãŒæ˜ç¢º
4. æ™‚é–“é…åˆ†: å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®é–‹å§‹æ™‚åˆ»ã‚’æ¨å®š

ã€å‡ºåŠ›å½¢å¼ã€‘
JSONã®ã¿ï¼ˆèª¬æ˜ä¸è¦ï¼‰:
{{
  "chapters": [
    {{
      "title": "â‘ ã€œã€œ",
      "start_sec": 0.0,
      "description": "ã‚»ã‚¯ã‚·ãƒ§ãƒ³å†…å®¹ã®ç°¡æ½”ãªèª¬æ˜"
    }},
    ...
  ]
}}

ã€å°æœ¬ã€‘
{transcript}
"""

    response = model.generate_content(prompt)
    result = response.text.strip()

    # Extract JSON
    if '```json' in result:
        result = result.split('```json')[1].split('```')[0].strip()
    elif '```' in result:
        result = result.split('```')[1].split('```')[0].strip()

    data = json.loads(result)
    chapters = data.get('chapters', [])

    # Fill end_sec
    for i, ch in enumerate(chapters):
        ch['end_sec'] = chapters[i + 1]['start_sec'] if i < len(chapters) - 1 else total_duration

    return chapters


def main():
    import argparse
    ap = argparse.ArgumentParser(description="Extract 4 chapter titles from SRT")
    ap.add_argument("srt_file", help="SRT file path")
    ap.add_argument("--output", help="Output JSON file")
    args = ap.parse_args()

    srt_path = Path(args.srt_file)
    segments = parse_srt(srt_path)

    if not segments:
        print(f"âŒ No segments in {srt_path}")
        sys.exit(1)

    total_duration = segments[-1]['end_sec']
    transcript = '\n'.join([s['text'] for s in segments])

    print(f"ğŸ“– Parsed {len(segments)} segments ({total_duration:.1f}s)")
    print(f"ğŸ¤– Analyzing with Gemini...")

    chapters = analyze_chapters(transcript, total_duration)

    print(f"\nâœ… Generated {len(chapters)} chapters:\n")
    for ch in chapters:
        print(f"{ch['title']}")
        print(f"  {ch['start_sec']:.1f}s - {ch['end_sec']:.1f}s")
        print(f"  {ch.get('description', '')}\n")

    output_data = {'total_duration': total_duration, 'chapters': chapters}

    if args.output:
        Path(args.output).write_text(json.dumps(output_data, ensure_ascii=False, indent=2), encoding='utf-8')
        print(f"ğŸ’¾ Saved: {args.output}")
    else:
        print(json.dumps(output_data, ensure_ascii=False, indent=2))


if __name__ == "__main__":
    main()
