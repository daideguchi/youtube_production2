[ops] run_id=ops__20260111T023634Z__314b32a4 mode=API exec_slot=0 lockdown=ON
[ops] API MODE: script pipeline is API-only (no THINK/CODEX).
[ops] help: `./ops patterns list` / `./ops latest --channel CHxx --video NNN`
/Users/dd/10_YouTube_Automation/factory_commentary/packages/factory_common/llm_router.py:331: FutureWarning: 

All support for the `google.generativeai` package has ended. It will no longer be receiving 
updates or bug fixes. Please switch to the `google.genai` package as soon as possible.
See README for more details:

https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md

  import google.generativeai as genai
INFO:LLMRouter:Router: cache hit for script_a_text_quality_judge (task_id=script_a_text_quality_judge__2ab062d41bf7ead83b4cf7c473e3b6a1)
INFO:LLMRouter:Router: Invoking fw_mixtral_8x22b_instruct for script_a_text_quality_fix...
INFO:httpx:HTTP Request: POST https://api.fireworks.ai/inference/v1/chat/completions "HTTP/1.1 400 Bad Request"
WARNING:LLMRouter:Failed to call fw_mixtral_8x22b_instruct: Error code: 400 - {'error': {'object': 'error', 'type': 'invalid_request_error', 'code': 'invalid_request_error', 'message': 'non-reasoning model does not support reasoning_effort'}} (status=400)
Traceback (most recent call last):
  File "/Users/dd/10_YouTube_Automation/factory_commentary/scripts/ops/script_runbook.py", line 1495, in <module>
    raise SystemExit(main())
                     ~~~~^^
  File "/Users/dd/10_YouTube_Automation/factory_commentary/scripts/ops/script_runbook.py", line 1491, in main
    return int(args.func(args))
               ~~~~~~~~~^^^^^^
  File "/Users/dd/10_YouTube_Automation/factory_commentary/scripts/ops/script_runbook.py", line 1249, in cmd_resume
    run_stage(ch, no, until, title=None)
    ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/dd/10_YouTube_Automation/factory_commentary/packages/script_pipeline/runner.py", line 10263, in run_stage
    fix_result = router_client.call_with_raw(
        task=fix_task,
        messages=[{"role": "user", "content": fixer_prompt}],
    )
  File "/Users/dd/10_YouTube_Automation/factory_commentary/packages/factory_common/llm_router.py", line 1600, in call_with_raw
    result = self._call_internal(
        task=task,
    ...<8 lines>...
        **kwargs,
    )
  File "/Users/dd/10_YouTube_Automation/factory_commentary/packages/factory_common/llm_router.py", line 2390, in _call_internal
    raise RuntimeError(f"All models failed for task '{task}'. tried={tried} last_error={last_error}.{hint}")
RuntimeError: All models failed for task 'script_a_text_quality_fix'. tried=['fw_mixtral_8x22b_instruct'] last_error=Error code: 400 - {'error': {'object': 'error', 'type': 'invalid_request_error', 'code': 'invalid_request_error', 'message': 'non-reasoning model does not support reasoning_effort'}}. Fallback is disabled (strict model selection). If you explicitly accept an alternative model, set allow_fallback=true for this task/call.
