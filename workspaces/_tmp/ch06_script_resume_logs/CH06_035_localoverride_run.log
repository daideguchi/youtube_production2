[ops] run_id=ops__20260111T030410Z__6dcfaec4 mode=API exec_slot=0 lockdown=ON
[ops] API MODE: script pipeline is API-only (no THINK/CODEX).
[ops] help: `./ops patterns list` / `./ops latest --channel CHxx --video NNN`
/Users/dd/10_YouTube_Automation/factory_commentary/packages/factory_common/llm_router.py:331: FutureWarning: 

All support for the `google.generativeai` package has ended. It will no longer be receiving 
updates or bug fixes. Please switch to the `google.genai` package as soon as possible.
See README for more details:

https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md

  import google.generativeai as genai
Traceback (most recent call last):
  File "/Users/dd/10_YouTube_Automation/factory_commentary/scripts/ops/script_runbook.py", line 1495, in <module>
    raise SystemExit(main())
                     ~~~~^^
  File "/Users/dd/10_YouTube_Automation/factory_commentary/scripts/ops/script_runbook.py", line 1491, in main
    return int(args.func(args))
               ~~~~~~~~~^^^^^^
  File "/Users/dd/10_YouTube_Automation/factory_commentary/scripts/ops/script_runbook.py", line 1249, in cmd_resume
    run_stage(ch, no, until, title=None)
    ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/dd/10_YouTube_Automation/factory_commentary/packages/script_pipeline/runner.py", line 10174, in run_stage
    verdict, judge_obj, _judge_result, _judge_raw = _run_judge(current_text or "", round_no=round_no)
                                                    ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/dd/10_YouTube_Automation/factory_commentary/packages/script_pipeline/runner.py", line 9409, in _run_judge
    judge_result = router_client.call_with_raw(
        task=judge_task,
        messages=[{"role": "user", "content": judge_prompt}],
        response_format="json_object",
    )
  File "/Users/dd/10_YouTube_Automation/factory_commentary/packages/factory_common/llm_router.py", line 1600, in call_with_raw
    result = self._call_internal(
        task=task,
    ...<8 lines>...
        **kwargs,
    )
  File "/Users/dd/10_YouTube_Automation/factory_commentary/packages/factory_common/llm_router.py", line 2390, in _call_internal
    raise RuntimeError(f"All models failed for task '{task}'. tried={tried} last_error={last_error}.{hint}")
RuntimeError: All models failed for task 'script_a_text_quality_judge'. tried=['or_deepseek_v3_2_exp'] last_error=No LLM client configured for provider(s): ['fireworks'] (set: FIREWORKS_SCRIPT). Fallback is disabled (strict model selection). If you explicitly accept an alternative model, set allow_fallback=true for this task/call.
