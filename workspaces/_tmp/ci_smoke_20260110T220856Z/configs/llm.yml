# Unified LLM configuration (models, tiers, tasks)
#
# LEGACY NOTICE:
# - This file exists for legacy tooling/tests compatibility (factory_common.llm_config / llm_client).
# - Normal ops routing SSOT is the slot-based router config:
#     - configs/llm_router.yaml (+ local)
#     - configs/llm_task_overrides.yaml (+ local)
#     - configs/llm_model_codes.yaml (+ local)
#     - configs/llm_model_slots.yaml (+ local) via LLM_MODEL_SLOT
#     - configs/llm_exec_slots.yaml (+ local) via LLM_EXEC_SLOT
# - The old registry files were archived and removed from the repo (2026-01-08).
#
# -------------------------------------------------------------------
# 2025-12-13 01:59:12 +0900
# Low-cost 3-rank routing (user directive; OpenRouter model IDs verified via /api/v1/models).
#
# Rank A (script / thinking required):
#   deepseek/deepseek-v3.2-exp
#   → moonshotai/kimi-k2-thinking
#
# Rank B (general):
#   deepseek/deepseek-v3.2-exp
#   → qwen/qwen-2.5-7b-instruct
#   → tencent/hunyuan-a13b-instruct
#   → google/gemma-3n-e2b-it:free
#
# Rank C (free-first):
#   google/gemma-3n-e2b-it:free
#   → tencent/hunyuan-a13b-instruct
#   → mistralai/mistral-7b-instruct:free
#   → qwen/qwen-2.5-7b-instruct
#
# NOTE: "Cypher Alpha (free)" was not present on OpenRouter at this timestamp,
# so Rank C fallback #2 uses `mistralai/mistral-7b-instruct:free`.
# NOTE: OpenRouter did not expose a `:free` variant for `tencent/hunyuan-a13b-instruct`
# at this timestamp (paid/low-cost), but it matches the "low cost" intent.
# -------------------------------------------------------------------

providers:
  azure:
    env_api_key: AZURE_OPENAI_API_KEY
    env_endpoint: AZURE_OPENAI_ENDPOINT
    default_api_version: "2025-04-01-preview"
    responses_api_version: "2025-04-01-preview"

  openrouter:
    env_api_key: OPENROUTER_API_KEY
    base_url: "https://openrouter.ai/api/v1"

  gemini:
    env_api_key: GEMINI_API_KEY

models:
  azure_gpt5_mini:
    provider: azure
    api_type: responses
    deployment: gpt-5-mini
    capabilities:
      allow_reasoning: true
      allow_json_mode: true
      allow_temperature: false
      allow_stop: false
      max_output_tokens: 128000

  azure_gpt5_chat:
    provider: azure
    api_type: chat
    deployment: gpt-5-chat
    capabilities:
      allow_reasoning: false
      allow_json_mode: true
      allow_temperature: true
      allow_stop: true
      max_output_tokens: 16384

  azure_tts_primary:
    provider: azure
    api_type: responses
    deployment: gpt-5-mini
    capabilities:
      allow_reasoning: true
      allow_json_mode: true
      allow_temperature: false
      allow_stop: false
      max_output_tokens: 128000

  or_qwen_free:
    provider: openrouter
    api_type: chat
    model: "qwen/qwen-2.5-72b-instruct:free"
    capabilities:
      allow_reasoning: false
      allow_json_mode: false
      allow_temperature: true
      allow_stop: true
      max_output_tokens: 4096

  or_llama_free:
    provider: openrouter
    api_type: chat
    model: "meta-llama/llama-3.3-70b-instruct:free"
    capabilities:
      allow_reasoning: false
      allow_json_mode: false
      allow_temperature: true
      allow_stop: true
      max_output_tokens: 4096

  or_deepseek_v3_2_exp:
    provider: openrouter
    api_type: chat
    model: "deepseek/deepseek-v3.2-exp"
    capabilities:
      allow_reasoning: false
      allow_json_mode: true
      allow_temperature: true
      allow_stop: true
      max_output_tokens: 16384

  or_kimi_k2_thinking:
    provider: openrouter
    api_type: chat
    model: "moonshotai/kimi-k2-thinking"
    capabilities:
      allow_reasoning: false
      allow_json_mode: true
      allow_temperature: true
      allow_stop: true
      max_output_tokens: 65535

  # Premium (expensive) — use ONLY when explicitly enabled (e.g. master-plan tier candidates).
  or_claude_opus_4_5:
    provider: openrouter
    api_type: chat
    model: "anthropic/claude-opus-4.5"
    capabilities:
      allow_reasoning: false
      allow_json_mode: false
      allow_temperature: true
      allow_stop: true
      max_output_tokens: 32000

  # or_o3_mini:
  #   provider: openrouter
  #   api_type: chat
  #   model: "openai/o3-mini"
  #   capabilities:
  #     allow_reasoning: true
  #     allow_json_mode: true
  #     allow_temperature: false
  #     allow_stop: false
  #     max_output_tokens: 16384

  or_qwen_2_5_7b_instruct:
    provider: openrouter
    api_type: chat
    model: "qwen/qwen-2.5-7b-instruct"
    capabilities:
      allow_reasoning: false
      allow_json_mode: false
      allow_temperature: true
      allow_stop: true
      max_output_tokens: 8192

  or_hunyuan_a13b_instruct:
    provider: openrouter
    api_type: chat
    model: "tencent/hunyuan-a13b-instruct"
    capabilities:
      allow_reasoning: false
      allow_json_mode: true
      allow_temperature: true
      allow_stop: true
      max_output_tokens: 16384

  or_gemma_3n_e2b_it_free:
    provider: openrouter
    api_type: chat
    model: "google/gemma-3n-e2b-it:free"
    capabilities:
      allow_reasoning: false
      allow_json_mode: true
      allow_temperature: true
      allow_stop: true
      max_output_tokens: 2048

  or_mistral_7b_instruct_free:
    provider: openrouter
    api_type: chat
    model: "mistralai/mistral-7b-instruct:free"
    capabilities:
      allow_reasoning: false
      allow_json_mode: true
      allow_temperature: true
      allow_stop: true
      max_output_tokens: 4096

  # Vision (image + text -> text), used for thumbnail captioning.
  or_qwen_2_5_vl_72b_instruct:
    provider: openrouter
    api_type: chat
    model: "qwen/qwen2.5-vl-72b-instruct"
    capabilities:
      allow_reasoning: false
      allow_json_mode: false
      allow_temperature: true
      allow_stop: true
      max_output_tokens: 8192

  gemini_2_5_flash_image:
    provider: gemini
    api_type: image
    model: gemini-2.5-flash-image
    capabilities:
      supports_aspect_ratio: true
      supports_size: false
      supports_negative_prompt: false
      supports_seed: true
      max_batch_n: 1

tiers:
  heavy_reasoning:
    - or_deepseek_v3_2_exp
    - or_kimi_k2_thinking
    # - or_o3_mini  # disabled by default (cost)

  standard:
    - or_deepseek_v3_2_exp
    - or_qwen_2_5_7b_instruct
    - or_hunyuan_a13b_instruct
    - or_gemma_3n_e2b_it_free

  cheap:
    - or_gemma_3n_e2b_it_free
    - or_hunyuan_a13b_instruct
    - or_mistral_7b_instruct_free
    - or_qwen_2_5_7b_instruct

  vision_caption:
    - or_qwen_2_5_vl_72b_instruct

  image_gen:
    - gemini_2_5_flash_image
  image:
    - gemini_2_5_flash_image

tasks:
  # Script pipeline (new flow)
  script_topic_research:
    tier: heavy_reasoning
    defaults:
      timeout: 300
      extra_body:
        reasoning:
          enabled: true
          exclude: true

  script_outline:
    tier: heavy_reasoning
    defaults:
      timeout: 180
      thinking_level: high
      extra_body:
        reasoning:
          enabled: true
          exclude: true

  script_chapter_brief:
    tier: heavy_reasoning
    defaults:
      timeout: 180
      thinking_level: high
      extra_body:
        reasoning:
          enabled: true
          exclude: true

  script_chapter_draft:
    tier: heavy_reasoning
    defaults:
      timeout: 240
      thinking_level: high
      extra_body:
        reasoning:
          enabled: true
          exclude: true

  script_chapter_review:
    tier: heavy_reasoning
    defaults:
      timeout: 180
      thinking_level: high
      extra_body:
        reasoning:
          enabled: true
          exclude: true

  script_cta:
    tier: heavy_reasoning
    defaults:
      timeout: 180
      thinking_level: high
      extra_body:
        reasoning:
          enabled: true
          exclude: true

  script_quality_check:
    tier: heavy_reasoning
    defaults:
      timeout: 300
      thinking_level: high
      extra_body:
        reasoning:
          enabled: true
          exclude: true

  script_format:
    tier: standard
    defaults:
      timeout: 60

  # Legacy script tasks (kept for compatibility)
  script_polish_ai:
    tier: heavy_reasoning
    defaults:
      thinking_level: low
      max_output_tokens: 4096

  script_draft:
    tier: heavy_reasoning
    defaults:
      thinking_level: low
      max_output_tokens: 4096

  script_rewrite:
    tier: heavy_reasoning
    defaults:
      thinking_level: low
      max_output_tokens: 4096

  quality_review:
    tier: heavy_reasoning
    defaults:
      thinking_level: low
      max_output_tokens: 4096

  context_analysis:
    tier: heavy_reasoning
    defaults:
      thinking_level: low
      max_output_tokens: 4096

  research:
    tier: standard

  review:
    tier: standard

  enhance:
    tier: standard

  general:
    tier: standard

  natural_command:
    tier: standard

  # TTS pipeline
  tts_annotate:
    tier: standard
    defaults:
      timeout: 30
      response_format: json_object
      max_output_tokens: 1400

  tts_text_prepare:
    tier: standard
    defaults:
      timeout: 60
      response_format: json_object
      max_output_tokens: 1500

  tts_segment:
    tier: standard
    defaults:
      timeout: 30
      response_format: json_object
      max_output_tokens: 1500

  tts_pause:
    tier: standard
    defaults:
      timeout: 30
      response_format: json_object
      max_output_tokens: 1200

  tts_reading:
    tier: heavy_reasoning
    defaults:
      timeout: 60

  audio_text:
    tier: standard

  # Visual pipeline
  visual_section_plan:
    tier: heavy_reasoning
    defaults:
      timeout: 120
      max_output_tokens: 8000

  # One-shot cue planning (segments → cue ranges + visual_focus)
  # Used to keep THINK MODE to a single pending task for srt2images.
  visual_image_cues_plan:
    tier: heavy_reasoning
    defaults:
      timeout: 180
      response_format: json_object
      max_output_tokens: 8000

  visual_persona:
    tier: heavy_reasoning
    defaults:
      timeout: 60
      max_output_tokens: 900

  visual_bible:
    tier: heavy_reasoning
    defaults:
      timeout: 180
      response_format: json_object
      max_output_tokens: 3200

  visual_prompt_refine:
    tier: heavy_reasoning
    defaults:
      timeout: 60
      max_output_tokens: 1200

  visual_image_gen:
    tier: image_gen
    defaults:
      timeout: 60
      aspect_ratio: "16:9"
      n: 1

  # Belt/Title helpers
  belt_generation:
    tier: standard
    defaults:
      timeout: 120
      response_format: json_object
      max_output_tokens: 1800

  title_generation:
    tier: standard
    defaults:
      timeout: 60
      max_output_tokens: 256

  # Thumbnails / captions (legacy)
  caption:
    tier: vision_caption
    defaults:
      max_output_tokens: 4096

  thumbnail_caption:
    tier: vision_caption
    defaults:
      max_output_tokens: 4096

  # Image generation (legacy entry)
  image_generation:
    tier: image
    defaults:
      aspect_ratio: "16:9"
      n: 1

  image_generation_gemini3:
    tier: image
    defaults:
      aspect_ratio: "16:9"
      n: 1

  # OpenRouter fallback placeholder
  openrouter_fallback:
    tier: cheap
