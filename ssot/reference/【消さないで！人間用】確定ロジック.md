## 音声生成処理の基本フロー

### 1. 音声生成準備
- Aテキスト（SoT）が存在することを確認:
  - 通常（下流互換）: `workspaces/scripts/{チャンネル}/{動画番号}/content/assembled.md`
  - 人手編集（UI）が入った場合: `workspaces/scripts/{チャンネル}/{動画番号}/content/assembled_human.md`
    - `assembled_human.md` がある場合はそれが正本、`assembled.md` は互換用 mirror として同期する
    - split-brain（差分）がある場合は **STOP** して明示解決する
- **台本本文に出典/脚注/URLなどのメタ情報を混入させない**（字幕に出る/読み上げる事故の根本原因）
  - 禁止例: `([戦国ヒストリー][13])` / `[13]` / `https://...` / `Wikipedia/ウィキペディア` を出典として直接書く表現
  - 出典は本文ではなく `content/analysis/research/references.json` 等へ集約する
  - 既に混入している場合は `scripts/sanitize_a_text.py` で退避→除去→同期してから再生成する
- **ポーズ挿入の区切り記号は `---` のみ**（1行単独）。`***` / `___` / `///` 等は使わない（TTSが不自然に途切れる原因）。
  - 全チャンネル共通のAテキスト品質ルール: `ssot/ops/OPS_A_TEXT_GLOBAL_RULES.md`

### 2. 音声生成実行（SoT=final）
- 固定: **final 配下に直接出力**（下流はここだけ参照すれば良い）
```
PYTHONPATH=".:packages" python3 packages/audio_tts/scripts/run_tts.py \
  --channel {チャンネルコード} --video {動画番号} \
  --input "workspaces/scripts/{チャンネル}/{動画番号}/content/assembled_human.md" \
  --out-wav "workspaces/audio/final/{チャンネル}/{動画番号}/{チャンネル}-{動画番号}.wav" \
  --log "workspaces/audio/final/{チャンネル}/{動画番号}/log.json"
```
※ `assembled_human.md` が無い場合は `assembled.md` を指定する。
- 音声生成エンジン（VOICEVOX/Voicepeak/ElevenLabs）は `packages/audio_tts/tts/routing.py` が決定。上書きする場合は `--engine-override` を指定する。
- 読み解決（Reading Resolution）はデフォで動作（コスト回避の手動運用は `SKIP_TTS_READING=1`）。
- **誤読防止（グローバル確定ルール）**:
  - VOICEVOX の実読（`audio_query.kana`）と、辞書/override適用後の期待読み（MeCab）を突合する（常時ON）。
  - 1件でも不一致があれば **停止**（誤読混入を禁止）し、レポートを `workspaces/scripts/{CH}/{VID}/audio_prep/reading_mismatches__*.json` に書く。
  - 修正は「辞書/override + **B側アノテーション（決定的）**」で行い、再合成する（フォールバックで続行しない）。
    - **AテキストはTTS目的で変更しない**（表示/内容のSoT）。Aの修正が必要になるのは「誤字/タイポで表示としても崩れている」場合に限る。
- 出力（正本）: `workspaces/audio/final/{チャンネル}/{動画番号}/`
  - `{チャンネル}-{動画番号}.wav`
  - `{チャンネル}-{動画番号}.srt`
  - `log.json`
  - `a_text.txt`（**実際に合成したTTS入力（=Bテキスト）のスナップショット**）
- `workspaces/scripts/{チャンネル}/{動画番号}/audio_prep/` は **中間領域**（Aテキスト入力でスクリプト更新時に自動 purge 対象）。下流のSoTにはしない。

### 3. CSVファイル更新
- 生成された音声ファイルを反映するために、`workspaces/planning/channels/{チャンネル}.csv` の該当動画行を以下のように更新：
  - 音声整形：`済`
  - 音声検証：`完了 Δ0.0ms tol=50ms YYYY-MM-DD`
  - 音声生成：`完了 YYYY-MM-DD`
  - 音声品質：`完了 YYYY-MM-DD`

### 4. 進捗確認
- CSVファイルの該当動画行が正しく更新されていること
- 音声ファイルが存在すること（`workspaces/audio/final/{チャンネル}/{動画番号}/` に `.wav`）
- 字幕ファイルが存在すること（同ディレクトリに `.srt`）
- を確認して、処理完了とする

## CapCutドラフト生成フロー（全チャンネル共通）
- 前提
  - `packages/video_pipeline/config/channel_presets.json` に各CHの capcut_template / layout / opening_offset / prompt_template が定義済み。
  - CapCutのテンプレートフォルダが `--draft-root` 配下に存在すること（例: `~/Movies/CapCut/User Data/Projects/com.lveditor.draft/CH01-UNK_道標_最新テンプレ`）。
  - **macOS権限注意**: 実行環境によっては CapCut の draft root（`~/Movies/CapCut/.../com.lveditor.draft`）が **読めても書けない**（`Operation not permitted`）ことがある。この場合 `video_pipeline.tools.auto_capcut_run` は自動で `workspaces/video/_capcut_drafts/` にフォールバックして生成する。CapCutで使うには、そのドラフトフォルダを CapCut draft root にコピーする（= Full Disk Access が必要）。
  - SRT はどのパスでもOK（デフォルトで `--prefer-tts-final=true` のため、episode を特定できれば `workspaces/audio/final/{CH}/{NNN}/{CH}-{NNN}.srt` を優先して使用）。
- 実行コマンド例（repo root で実行）
```
PYTHONPATH=".:packages" python3 -m video_pipeline.tools.auto_capcut_run \
  --channel CH01 \
  --srt workspaces/video/input/CH01_人生の道標/220.srt \
  --out workspaces/video/runs/jinsei220 \
  --draft-root "$HOME/Movies/CapCut/User Data/Projects/com.lveditor.draft" \
  --nanobanana direct \
  --crossfade 0.5 \
  --imgdur 20 \
  --fps 30 \
  --belt-mode llm \
  --resume false
```
- 内部処理の順序（auto_capcut_run.py）
  1) `packages/video_pipeline/tools/run_pipeline.py` を呼び出し、channel preset に従って LLM分割→image_cues.json 生成（`--channel`必須、CH01は pace 12s/カット、他は preset base_period）。画像も同時生成。  
  2) ベルト生成: `belt_mode` 既定は `llm`（image_cues からLLM生成）。`existing` を指定すると run_dir 内の belt_config.json をそのまま使い、なければスキップ。`equal`/`grouped` は labels や chapters/episode_info.json が必要。  
  3) `packages/video_pipeline/tools/capcut_bulk_insert.py` でテンプレ複製→opening_offset をテンプレトラックに適用→image_cues.json に沿って画像/字幕を配置。テンプレート名は `--template` 未指定なら preset capcut_template を自動使用。CapCut側には tx=0, ty=0, scale=1.03, crossfade=args.crossfade で挿入。  
  4) `packages/video_pipeline/tools/inject_title_json.py` でタイトルを draft JSON に注入（生成タイトル or `--title`）。`auto_run_info.json` に実行メタを書き出し。
  - 主要設定ポイント
    - **SRT正本**: デフォルトで `--prefer-tts-final=true`。指定した `--srt` が別場所でも、episode を特定できれば final を優先して使う（古いSRTでドラフト作る事故を防止）。  
    - **整合チェック（必須）**: `timeline_manifest.json` が生成されていること（`wav長 ≒ srt終端 ≒ cues終端` を厳格検証し、ズレ事故を検知する“契約”）。  
    - **CapCutテンプレ自動修復**: テンプレが `draft_info.json` のみ／空トラック名／重複トラック名でも、`packages/video_pipeline/tools/capcut_bulk_insert.py` が **複製直後に `draft_content.json`/`draft_info.json` を復元し、トラック名を正規化してからロード**する（レイヤ落ち・別テンプレ混入事故の根治）。監査は `PYTHONPATH=".:packages" python3 -m video_pipeline.tools.validate_capcut_templates --active-only`。  
    - **テンプレのプレースホルダ掃除（重要）**: テンプレ内に残っている `video_2` / `text_2` などの **汎用名トラック**（`^(video|text)_\\d+$`）は、複製直後に **必ず segments を空にしてから** srt2images/subtitles を挿入する（画像レイヤ二重化・無関係テキスト混入事故を根絶）。重要レイヤは必ず固有名（例: `logo`, `main_belt`, `dreamy_confetti`）にして汎用名にしない。  
    - **ドラフト名のSoT（重要）**: `video_pipeline.tools.auto_capcut_run` は `workspaces/planning/channels/{CH}.csv` の `タイトル` を使い、`★{CH}-{NNN}-{タイトル}` の **安定名で上書き生成**する（timestamp draft を量産しない／誤ドラフトを開く事故を防ぐ）。  
    - **画像の意味整合（最重要）**: 各cueの画像は **「そのセクション（区切ったキュー）の内容を正確に表現する」** こと。**絶対禁止**: キーワード辞書・固定モチーフ・固定プール等で主題を機械置換/自動決め打ちする（例: 「時間」→時計/懐中時計）。抽象・比喩でも、当該セクションの具体的な行動/物体/状況に必ず紐づけ、同じ象徴を連発しない。曖昧なら `visual_cues_plan.json` を先に直す（pending→ready）。また **禁止例の具体列挙はプロンプト上のprimingになり得る** ため、実運用のプロンプトでは禁止カテゴリを一般化して書く（例: cliché symbols）。
	    - **FLUX schnell の類似画像対策（重要）**: `fireworks_flux_1_schnell_fp8` はプロンプト長が短く、長文テンプレ/ガードレールは内部で短縮されて **cue間の差分が潰れやすい**（=同じ構図/同じ場所の量産が起きる）。対策は 3 点:
	      1) schnell 時は **短いプロンプト**に寄せ、長い suffix や禁止例の具体列挙（priming）を落とす（実装: `packages/video_pipeline/src/srt2images/prompt_builder.py`）。
	      2) **cueごとに安定 seed を付与**して収束を回避しつつ再現性を担保する（`image_cues.json` に `seed`、環境で `SRT2IMAGES_CUE_SEED_MODE=off|fixed|<default>`）。
	      3) cue間の差分は **LLM/THINK の推論結果（`visual_cues_plan.json` の `refined_prompt` 等）**で担保する（勝手なローカルheuristicで決め打ちしない）。特に schnell は `refined_prompt` を必須にし、各cueの短い英語プロンプトに camera angle/distance・pose/action・setting/props・lighting を入れ、隣接で同じ構図/同じ場所にならないようにする。曖昧/類似が出たら `visual_cues_plan.json` を修正して再実行する。
	      - 補足（2026-01-11）: Batch運用（Gemini）を実装できたら、動画内画像（`visual_image_gen`）の既定は **Gemini（Batch）へ寄せる**（正本: `ssot/DECISIONS.md:D-016`）。schnell は必要時の明示選択へ（削除はしない）。
    - **画像なしドラフト（注意）**: `--nanobanana none` は **外部画像生成を止める**ため、run_dir の `images/*.png` を **PLACEHOLDER** で埋める（CapCut上も白い疑似画像に見える＝挿入漏れではなく仕様）。後から画像を入れるなら `PYTHONPATH=".:packages" python3 -m video_pipeline.tools.regenerate_images_from_cues --run <run_dir> --channel <CH> --overwrite` → 必要に応じて `auto_capcut_run --belt-mode existing --resume` でドラフトを上書き再生成（ドラフト側の同期が崩れたら `sync_srt2images_materials --draft <draft_dir>`）。
    - **テンプレ本体の恒久クリーン**（定期）:
      - 正規化（backup付き）: `PYTHONPATH=".:packages" python3 -m video_pipeline.tools.normalize_capcut_templates --active-only --run`
      - 厳格監査（empty/dup を許さない）: `PYTHONPATH=".:packages" python3 -m video_pipeline.tools.validate_capcut_templates --active-only --strict-names`
    - **字幕スタイル**: `subtitles_text` は SSOT `jinsei_standard_v2`（黒背景）を優先して正規化する（CapCutの「デフォルト挿入」見た目に寄せる）。  
	    - **SRT改行整形（標準）**: 字幕の視認性のため、final SRTは改行整形済みを使う（SSOT: `ssot/ops/OPS_SRT_LINEBREAK_FORMAT.md`）。未整形の場合は `python3 scripts/format_srt_linebreaks.py workspaces/audio/final/{CH}/{NNN}/{CH}-{NNN}.srt --in-place`（改行のみ、本文不変）を実行してからドラフトへ注入する。
    - opening_offset: presetの `belt.opening_offset` を使用（例: CH01=0.0s。0.0s が多いが 3.0s のCHもある）。CapCutトラックをシフト済み。  
    - layout/position: presetの position(tx,ty,scale) と layout(beltTopPct 等) を適用。  
    - style/prompt: presetの prompt_template + prompt_suffix + tone_profile を使用。文字禁止・人物一貫のガードレールはテンプレに強制付与。  
    - ベルト: 既定は `belt_mode=llm`。既存を使う場合のみ `--belt-mode existing`（belt_config.json が無い場合はスキップされる）。均等4分割は `equal`+labels、日本語必須。章構成から作る場合は `grouped`+chapters/episode_info.json。  
    - 再実行/部分更新: `--resume` で既存 run_dir の cues/images を再利用。`--fallback-if-missing-cues` で欠損時のみ再生成。  
    - 確認: 出力先 `workspaces/video/runs/{run_name}/` に `image_cues.json`, `capcut_draft/`, `capcut_draft_info.json`, `auto_run_info.json` が揃っていることを確認。
    - **古い/壊れたドラフト整理（定期）**: 完成版（`★CHxx-...`）と active template 以外を CapCut root から退避する → `PYTHONPATH=".:packages" python3 -m video_pipeline.tools.clean_capcut_channel_drafts --channel CH05 --apply`（`~/Movies/CapCut/Archive_*/CH05/` に移動）

### 補足: チャンネル別挙動・テンプレSSOT
- CH01の「220」系ロジックは生存中。`packages/video_pipeline/src/srt2images/cue_maker.py` でCH01のみ `base_seconds=12` を強制し、LLM文脈分割を使って細かいカットを作る（機械20s分割はフォールバック扱い）。他CHは `channel_presets.image_generation.base_period` を参照（デフォルト30s、CH02はconfigで9s）。
- テンプレ/設定の正本:
  - `packages/video_pipeline/config/channel_presets.json`: チャンネルごとの capcut_template / belt / layout / prompt_template / suffix 等。
- `packages/video_pipeline/config/template_registry.json`: 画像プロンプトテンプレのSoT（`channel_presets.json` の `prompt_template` は登録必須 / lint: `PYTHONPATH=".:packages" python3 -m video_pipeline.tools.validate_prompt_template_registry`）。
    - scope: `["CHxx", ...]`=チャンネル既定 / `["legacy"]`=旧（混乱防止のため `inactive` を使う）
    - status: `active`=運用 / `inactive`=残してOKだが運用では使わない
- 環境変数: 上の「環境変数の恒久ロード」を参照（`.env` 一本化）。
- LLMメタログ: `packages/video_pipeline/src/srt2images/llm_context_analyzer.py` は `call_with_raw` 経由で request_id / chain / latency / usage を `workspaces/logs/llm_context_analyzer.log` に jsonl で記録（なければ従来call）。LLM全体のusageは `workspaces/logs/llm_usage.jsonl`（router）で集計でき、`scripts/llm_usage_report.py` で要約可能。
- LLMログ統合レポート: `scripts/llm_logs_combined_report.py` で `workspaces/logs/llm_usage.jsonl` / `workspaces/logs/llm_context_analyzer.log` / `workspaces/logs/tts_llm_usage.log` をまとめて要約（件数・モデル/プロバイダ内訳・レイテンシ・トークン合計・last request_id）。監視/定期集計に利用可。
- CIアーティファクト: `llm_smoke` ワークフローが実行後に LLM系ログ (`workspaces/logs/llm_usage.jsonl`, `workspaces/logs/llm_context_analyzer.log`, `workspaces/logs/tts_llm_usage.log`) をアーティファクトとして保存する（存在する場合のみ。無ければスキップ）。
- CapCutドラフト生成チェックリスト（簡易）:
  1) `.env` が正しく読み込まれているか `./scripts/with_ytm_env.sh python3 scripts/check_env.py` で確認（env/PYTHONPATHの取りこぼしを防ぐ）。
  2) `workspaces/planning/channels/CHxx.csv` に台本パス/企画意図/タグが入っていることを確認し、テンプレ選択は `packages/video_pipeline/config/channel_presets.json` + `packages/video_pipeline/config/template_registry.json` に存在するものを使う（CH06ダークは `watercolor_gold_blue_ch06_dark.txt`、CH01は 220 ロジック生存で base_period=12s 固定）。
  3) `PYTHONPATH=".:packages" python3 -m video_pipeline.tools.auto_capcut_run ...` を実行。`--resume` で再利用、`--belt-mode existing` で既存ベルトを尊重する。`workspaces/video/runs/{run_name}/auto_run_info.json` を必ず確認。
  4) 生成物確認: `image_cues.json` の `llm_context` に企画意図・タグが入っているか、CapCut draft が `opening_offset` 付きでシフトされているか、画像/字幕の件数がSRT行数と一致しているか。
  5) 画像生成は `image_cues.json` で組み立てたプロンプトを `ImageClient(task=\"visual_image_gen\")` に渡す（正本: `configs/image_models.yaml`）。モデルは `packages/video_pipeline/config/channel_presets.json: image_generation.model_key` でチャンネル別に固定し、未指定は tier 既定（Gemini）。ズレを見つけたら CSV更新→再実行（CSVは都度読み込みのため refresh は不要）。古いSRT起因のズレは `PYTHONPATH=\".:packages\" python3 -m video_pipeline.tools.align_run_dir_to_tts_final --run <run_dir>` で retime。
  6) テンプレ管理: 運用で使う画像プロンプトテンプレは `packages/video_pipeline/config/template_registry.json` の `status=active` のみ。`channel_presets.json` の `prompt_template` が参照するテンプレは必ず registry に登録し、不要/旧テンプレは `inactive` に落として残す（混乱防止）。

### CH01 固有（220ロジック・きめ細かいカット）
- 分割ロジック: `packages/video_pipeline/src/srt2images/cue_maker.py` で CH01 のみ `base_seconds=12` を強制。LLM文脈分割を優先し、秒数固定のフォールバックは補助扱い。
- CapCut: 開始オフセットは preset の `opening_offset`（現在 CH01=0.0s）。テンプレは `jinsei_warm_gold_blue_strict.txt` を channel scope から自動選択。
- 画像生成: セクション文脈＋企画CSVタグをプロンプトへ反映し、`ImageClient(task=\"visual_image_gen\")` で生成する（CH01は preset で Max 固定）。`image_cues.json` に企画意図・タグが入っていることを確認。
- コマンド例: `PYTHONPATH=".:packages" python3 -m video_pipeline.tools.auto_capcut_run --channel CH01 --srt workspaces/video/input/CH01_人生の道標/220.srt --out workspaces/video/runs/jinsei220 --draft-root "$HOME/Movies/CapCut/User Data/Projects/com.lveditor.draft" --nanobanana direct --crossfade 0.5 --imgdur 20 --fps 30 --belt-mode llm`

### CH06 固有（CH06-テンプレ固定 / 量産ドラフト）
- **絶対ルール**: コピー元テンプレは必ず `CH06-テンプレ`（他テンプレ混入はNG）。
- SoT: `workspaces/video/runs/CH06-NNN_capcut_v1/timeline_manifest.json`
  - `wav長 ≒ srt終端 ≒ cues終端` が一致していること（ズレがあれば `PYTHONPATH=".:packages" python3 -m video_pipeline.tools.align_run_dir_to_tts_final --run <run_dir>` で retime。LLMなし）。
- クリーン再生成（画像タイムライン + テンプレ構造を維持）:
  - `PYTHONPATH=".:packages" python3 -m video_pipeline.tools.rebuild_ch06_drafts_from_template --draft-root "$HOME/Movies/CapCut/User Data/Projects/com.lveditor.draft" --template "CH06-テンプレ" --runs-root workspaces/video/runs --channel-csv workspaces/planning/channels/CH06.csv --videos 2-30`
- 音声＋字幕をSoT(manifest)から注入（黒背景）:
  - `PYTHONPATH=".:packages" python3 -m video_pipeline.tools.patch_draft_audio_subtitles_from_manifest --run workspaces/video/runs/CH06-002_capcut_v1`
  - 002〜030を同様に実行（再実行しても増殖しない / `draft_info.json` と `draft_content.json` を同期してレイヤカオスを防止）。

### 企画CSVの参照・UI
- `configs/sources.yaml` に CH01〜CH11 全ての planning CSV と persona を登録済み。script/image/音声パイプラインは常に最新 CSV を参照（`packages/script_pipeline/runner.py` の `planning_csv` ロード）。
- UI `/planning` で `workspaces/planning/channels/CHxx.csv` を直接表示して確認できる。企画が変わったら CSV を更新→再実行（CSVは都度読み込みのため refresh は不要）。
- 企画→台本への伝播を担保したいときは、CSV更新後に当該話数のステータスをリセットするか、再生成ジョブを実行してメタデータを取り込み直す。

### 環境変数の恒久ロード
- `.env` はリポジトリ直下に一本化。
- 入口固定: `./scripts/with_ytm_env.sh <cmd>`（`.env` export + `PYTHONPATH` 固定）で実行する。
- Python:
  - Homebrew Python は標準ライブラリ側の `sitecustomize` が先に読み込まれるため、sitecustomize による自動ロードは採用しない（wrapper/_bootstrap を正とする）。
  - `packages/audio_tts/scripts/run_tts.py` と `packages/factory_common/llm_router.py` は python-dotenv があれば `override=True` で明示ロード（事故防止）。
- FastAPI（apps/ui-backend）:
  - 起動スクリプト（`scripts/start_all.sh` / `apps/ui-backend/tools/start_manager.py`）が `.env` を読み込んで env を確定する。
  - backend 本体は不足キーのみ `.env` を参照する（起動時に全キーを読むわけではない）。

### リテイク（台本/音声）運用
- デフォルトは `redo_script=true` / `redo_audio=true`（人が確定したら false に落とす運用）。
- `台本リセット`（`POST /api/meta/script_reset/{CH}/{NNN}`）をしても `metadata.redo_note`（リテイクメモ）は維持する。`redo_script/redo_audio` は未設定に戻るためデフォルト（`true` 扱い）に戻る。
- API:
  - GET `/api/redo?channel=CH02&type=script|audio|all` … リテイク対象のみ抽出。
  - GET `/api/redo/summary?channel=CH02` … チャンネルごとのリテイク件数（script/audio/both）サマリ。
  - PATCH `/api/channels/{channel}/videos/{video}/redo` … フラグとメモを更新（redo_note）。
- UI: 企画CSVページでリテイクバッジ表示、フィルタ「リテイクのみ」、詳細モーダルで台本/音声リテイクON/OFFとメモを編集＆保存。
- CLI: `scripts/list_redo.py` でリストアップ、`scripts/mark_redo_done.py` で一括クリア（`--channel CH02 --videos 019 020` など）。
- ジョブ運用: `GET /api/redo` あるいは `scripts/list_redo.py` で対象抽出→再処理→成功時にフラグを false へ（`mark_redo_done.py` でクリア）。未設定は自動で true と見なす。

### 2025-12-12 追加メモ（環境・CapCut・テンプレ・画像文脈）
- `.env` 一本化の恒久策:  
  - 入口固定: `./scripts/with_ytm_env.sh <cmd>` で `.env` を export してから実行（CWD/PYTHONPATHの取りこぼしを防ぐ）。  
  - Python: Homebrew Python の `sitecustomize` 競合があるため、sitecustomize による自動ロードは採用しない（CLI実行は上記 wrapper を使う）。  
  - FastAPI（apps/ui-backend）: `scripts/start_all.sh` / `apps/ui-backend/tools/start_manager.py` 起動時に `.env` を読み込んで env を確定する（backend 本体は不足キーのみ `.env` を参照する）。  
  - 健全性チェック: `./scripts/with_ytm_env.sh python3 scripts/check_env.py` で主要キーの有無を確認。  
- CapCutドラフト CH01 220 ロジック確認:  
  - `cue_maker.py` の CH01 分岐で `base_seconds=12`＋LLM文脈分割を継続。細かいカットとアングル変化は 220 ロジックが生存。  
  - 画像生成は `llm_context` に企画CSVの情報を詰めて渡す（CSVは都度読み込みのため refresh は不要）。  
  - SRT は `workspaces/video/input/CH01_人生の道標/220.srt` を指定し、`--belt-mode llm` / `--crossfade 0.5` / `--imgdur 20` / `--fps 30` が既定。  
  - 実行後は `workspaces/video/runs/{run_name}/image_cues.json` の `llm_context` と `auto_run_info.json` を必ず確認。  
- テンプレ整理（画像プロンプト）:
  - SoT: `packages/video_pipeline/config/template_registry.json`
  - `packages/video_pipeline/config/channel_presets.json` の `prompt_template` が参照するテンプレは **registryに登録必須**（lint: `PYTHONPATH=".:packages" python3 -m video_pipeline.tools.validate_prompt_template_registry`）。
  - `packages/video_pipeline/templates/` には active / legacy が混在し得るが、**運用で使うのは registry の active**（legacyは残してもOK。混乱防止のため status を `inactive` にしておく）。  
- サムネ・企画CSV UI: `/planning` で CSV をサムネ付きで確認でき、リテイクON/OFFとメモをモーダルから編集可能（デフォルト true）。タイルはチャンネルアイコンで切替可、モーダルの閉じるボタンは明色で視認性を確保。  
- 最終音声の入力ガード:
  - 入口固定: `/api/audio-tts/run-from-script` を使う（入力SoTは **`assembled_human.md -> assembled.md` に固定**し、`script_sanitized.txt` は毎回 A から生成して使う）。
  - `script_sanitized.txt` / `script_audio_human.txt` / `b_text*.txt` などが残っていても、標準フローでは **入力として自動採用しない**（暗黙フォールバック禁止）。
  - 例外（手動/明示）: B（TTS入力）を人手で直して再生成したい場合は、`audio_prep/script_sanitized.txt`（または `final/a_text.txt`）を **明示入力**にする（無ければ失敗。Aへ戻さない）。
    - UI（Episode Studio の B保存）: `content/script_audio_human.txt` を保存し、同内容を `audio_prep/script_sanitized.txt` に mirror する（再生成の入口は `script_sanitized.txt` 側に固定）。
  - `packages/audio_tts/scripts/run_tts.py` の安全ガード:
    - A split-brain（`assembled_human.md` と `assembled.md` が差分）:
      - human が新しい: `assembled.md` を human に同期（.bak付き）
      - assembled が新しい（または同時刻）: **STOP（CONFLICT）** → `scripts/episode_ssot.py confirm-a --prefer human|assembled`
    - B stale:
      - Bが `sanitize(A)` と一致せず、かつ BがAより古い場合は **STOP（STALE）**
- 音声成功時は `redo_audio=false` を自動クリア（台本側のフラグは維持）。

### VOICEVOX公式ユーザー辞書同期（正規ルート）
- VOICEVOXエンジンの公式ユーザー辞書API（`voicevox_engine` README準拠）を利用できるようにしてある。
  - 参照: `GET /user_dict`
  - 追加: `POST /user_dict_word?surface=...&pronunciation=...&accent_type=...`
  - 更新: `PUT /user_dict_word/{word_uuid}?surface=...&pronunciation=...&accent_type=...`
  - 削除: `DELETE /user_dict_word/{word_uuid}`
- 実装:
  - クライアント: `packages/audio_tts/tts/voicevox_user_dict.py`
  - 同期スクリプト: `packages/audio_tts/scripts/sync_voicevox_user_dict.py`
- 使い方（例）:
  - 運用固定（グローバル確定語のみ）: `PYTHONPATH=".:packages" python3 -m audio_tts.scripts.sync_voicevox_user_dict --global-only`
  - `PYTHONPATH=".:packages" python3 packages/audio_tts/scripts/sync_voicevox_user_dict.py --channel CH05`
  - 全チャンネル同期: `... --all`
  - 既存surfaceを更新したいとき: `... --overwrite`
  - 変更せず内容確認だけ: `... --dry-run`
- accent_type は公式API必須。repo辞書側に無い場合は、同スクリプトが `audio_query` で推定して登録する（チャンネルの `voice_config.json` の speaker_id を優先）。

### 読み辞書の“正”と使い分け（確定ルール）
- **正本（canonical）は repo 内辞書。VOICEVOX公式辞書は派生物。**
  - チャンネル別辞書: `packages/audio_tts/data/reading_dict/CHxx.yaml`
    - 全動画で再現性を担保するための唯一のソース。
    - 同じsurfaceが複数動画で再発したらここに昇格。
  - 全体共通の確定語（人間レビュー済）: `packages/audio_tts/data/global_knowledge_base.json`
    - どのチャンネルでも読みが一意で、公式ユーザー辞書へも同期して良い語だけを置く。
  - 全体共通の安定置換: `packages/audio_tts/configs/learning_dict.json`
    - 自動学習/補助の「前処理置換」層（strict B生成には使う）。
    - 公式ユーザー辞書へは **自動同期しない**（量が多く、事故リスクが上がるため）。
    - 公式辞書へ入れたい確定語は、`global_knowledge_base.json` に昇格してから同期する。
  - 動画単位の例外: `local_token_overrides.json`
    - 文脈依存/単発の誤読だけを潰す一時層。再発したらCH辞書へ昇格。
- VOICEVOX公式ユーザー辞書:
  - ローカルでの手動TTSやエディタ利用の安定化のための“キャッシュ層”。
  - 公式ユーザー辞書は `sync_voicevox_user_dict.py` で repo 辞書から同期して作る。
  - 公式辞書を手で直した場合は **必ず repo 側にも同じ修正を入れる**（正が逆転しないように）。

### 読みアノテーション（漢字,かな 等）の確定ロジック
- **Aテキストに読みを併記しない**（字幕も汚れ、TTSで二重読みになりやすい）。
  - 禁止例: `刈羽郡、かりわぐん` / `大河内正敏（おおこうちまさとし）`
  - 方針: **Aは表示/内容のSoTとして保ち**、読み最適化は **辞書/override/B入力** に寄せる。
- 既に混入している場合の扱い（意味を変えない最小修正）:
  1) **Aはそのまま保持**（表示/内容SoT。TTS目的で削らない）
  2) `run_tts` の B 生成（`audio_tts.tts.arbiter`）で **重複読み注釈だけ**を決定的に除去（例: `刈羽郡、かりわぐんから` → Bでは `刈羽郡から`）
     - ルール（Bのみ / 確定）: `X（Y）` / `X、Y` の `Y` が **かな/カナ**（読みヒント）なら **どちらか片方だけ**にする（2回読ませない）。
       - `X` が辞書登録して安全（2文字以上・曖昧語でない）なら `X` 側を採用し、`Y` は除去する（辞書/overrideで `X→reading` を確定し、Bでは `reading` に置換される）。
       - `X` が曖昧語/短すぎる等で辞書登録できないなら `Y` 側を採用し、`X` は除去する（辞書事故を避ける）。
  3) 読みは辞書/overrideで補う（再発/一意ならCH辞書へ、曖昧ならローカルへ）
  4) Aの修正は「誤字/タイポで表示としても崩れている」場合のみ（TTS目的では触らない）
- 辞書/override の使い分け（再掲・運用の結論）:
  - **一意の読み**（どの文脈でも事故らない）→
    - 全CH共通なら `packages/audio_tts/data/global_knowledge_base.json`
    - CH内だけなら `packages/audio_tts/data/reading_dict/CHxx.yaml`
    - → `sync_voicevox_user_dict.py` で公式辞書へ反映（運用固定: `--global-only`）
  - **曖昧語/文脈依存**（例: `行ったり` は「イッタリ/オコナッタリ」等に揺れうる）→ **辞書に入れない**。`audio_prep/local_token_overrides.json` で位置指定（語句全体で登録する例: `行ったり来たり` など）
- B（TTS入力）でのみ表記を崩したい場合:
  - `audio_prep/script_sanitized.txt`（または `final/a_text.txt`）を **明示入力**にして再生成する（Aへ戻さない）。

※ VOICEVOX/VOICEPEAK 別の「アノテーションの流れ」/「Bテキスト理想系」/「辞書の階層」は `ssot/ops/OPS_AUDIO_TTS.md` の「7章」「8章」を正本とする。
