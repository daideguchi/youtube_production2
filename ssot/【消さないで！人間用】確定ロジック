## 音声生成処理の基本フロー

### 1. 音声生成準備
- 各動画番号の `assembled.md` スクリプトファイルが `script_pipeline/data/{チャンネル}/{動画番号}/content/` に存在することを確認

### 2. 音声生成実行
- 以下のコマンドを使用して、各動画に対して音声生成を実行：
```
PYTHONPATH=. python audio_tts_v2/scripts/run_tts.py --channel {チャンネルコード} --video {動画番号} --input "script_pipeline/data/{チャンネル}/{動画番号}/content/assembled.md"
```
- 音声生成にはVOICEVOXエンジンが使用され、指定されたキャラクターの声が適用される
- LLMにより読み方の判定と修正が行われる（Reading Resolution）
- 音声ファイルは `{チャンネル}/{動画番号}/audio_prep/{チャンネル}-{動画番号}.wav` として保存される
- 字幕ファイルは `{チャンネル}/{動画番号}/audio_prep/{チャンネル}-{動画番号}.srt` として保存される

### 3. CSVファイル更新
- 生成された音声ファイルを反映するために、`progress/channels/{チャンネル}.csv` の該当動画行を以下のように更新：
  - 音声整形：`済`
  - 音声検証：`完了 Δ0.0ms tol=50ms YYYY-MM-DD`
  - 音声生成：`完了 YYYY-MM-DD`
  - 音声品質：`完了 YYYY-MM-DD`

### 4. 進捗確認
- CSVファイルの該当動画行が正しく更新されていること
- 音声ファイルが存在すること（`script_pipeline/data/{チャンネル}/{動画番号}/audio_prep/`に.wavファイル）
- 字幕ファイルが存在すること（.srtファイル）
- を確認して、処理完了とする

## CapCutドラフト生成フロー（全チャンネル共通）
- 前提
  - `commentary_02_srt2images_timeline/config/channel_presets.json` に各CHの capcut_template / layout / opening_offset / prompt_template が定義済み。
  - CapCutのテンプレートフォルダが `--draft-root` 配下に存在すること（例: `~/Movies/CapCut/User Data/Projects/com.lveditor.draft/CH01-UNK_道標_最新テンプレ`）。
  - 対応SRTが `commentary_02_srt2images_timeline/input/{CHxx_*}/` にあること。
- 実行コマンド例（ディレクトリ `commentary_02_srt2images_timeline/` で実行）
```
python tools/auto_capcut_run.py \
  --channel CH01 \
  --srt input/CH01_人生の道標/220.srt \
  --out output/jinsei220 \
  --draft-root "$HOME/Movies/CapCut/User Data/Projects/com.lveditor.draft" \
  --nanobanana direct \
  --crossfade 0.5 \
  --imgdur 20 \
  --fps 30 \
  --belt-mode llm \
  --resume false
```
- 内部処理の順序（auto_capcut_run.py）
  1) `tools/run_pipeline.py` を呼び出し、channel preset に従って LLM分割→image_cues.json 生成（`--channel`必須、CH01は pace 12s/カット、他は preset base_period）。画像も同時生成。  
  2) ベルト生成: `belt_mode` 既定は `llm`（image_cues からLLM生成）。`existing` を指定すると run_dir 内の belt_config.json をそのまま使い、なければスキップ。`equal`/`grouped` は labels や chapters/episode_info.json が必要。  
  3) `tools/capcut_bulk_insert.py` でテンプレ複製→opening_offset をテンプレトラックに適用→image_cues.json に沿って画像/字幕を配置。テンプレート名は `--template` 未指定なら preset capcut_template を自動使用。CapCut側には tx=0, ty=0, scale=1.03, crossfade=args.crossfade で挿入。  
  4) `tools/inject_title_json.py` でタイトルを draft JSON に注入（生成タイトル or `--title`）。`auto_run_info.json` に実行メタを書き出し。
  - 主要設定ポイント
    - opening_offset: presetの `belt.opening_offset` を使用（CH01=3.0s、他CHは0が多い）。CapCutトラックをシフト済み。  
    - layout/position: presetの position(tx,ty,scale) と layout(beltTopPct 等) を適用。  
    - style/prompt: presetの prompt_template + prompt_suffix + tone_profile を使用。文字禁止・人物一貫のガードレールはテンプレに強制付与。  
    - ベルト: 既定は `belt_mode=llm`。既存を使う場合のみ `--belt-mode existing`（belt_config.json が無い場合はスキップされる）。均等4分割は `equal`+labels、日本語必須。章構成から作る場合は `grouped`+chapters/episode_info.json。  
    - 再実行/部分更新: `--resume` で既存 run_dir の cues/images を再利用。`--fallback-if-missing-cues` で欠損時のみ再生成。  
    - 確認: 出力先 `output/{run_name}/` に `image_cues.json`, `capcut_draft/`, `capcut_draft_info.json`, `auto_run_info.json` が揃っていることを確認。

### 補足: チャンネル別挙動・テンプレSSOT
- CH01の「220」系ロジックは生存中。`src/srt2images/cue_maker.py` でCH01のみ `base_seconds=12` を強制し、LLM文脈分割を使って細かいカットを作る（機械20s分割はフォールバック扱い）。他CHは `channel_presets.image_generation.base_period` を参照（デフォルト30s、CH02はconfigで9s）。
- テンプレ/設定の正本:
  - `commentary_02_srt2images_timeline/config/channel_presets.json`: チャンネルごとの capcut_template / belt / layout / prompt_template / suffix 等。
  - `commentary_02_srt2images_timeline/config/template_registry.json`: テンプレ一覧とscope。CH06のダーク水彩テンプレ `watercolor_gold_blue_ch06_dark.txt` を登録済み。`jinsei_standard_illustration.txt` などlegacyテンプレは削除済み（UIのCH01固定2択も撤廃し、registryベースの一覧のみ表示）。
  - グローバル（manual scope）は ad-hoc 利用用、channel scope がデフォルト。legacy scope は廃止・非推奨。
- 環境変数の恒久対策: `sitecustomize.py` と `factory_common/image_client.py` がリポジトリ直下/ホームの `.env` を自動読込し、`os.environ.setdefault` で全プロセスに伝播する。`GEMINI_API_KEY` は `.env` に入れておけばPythonをどこから起動しても拾う。
- LLMメタログ: `commentary_02_srt2images_timeline/src/srt2images/llm_context_analyzer.py` は `call_with_raw` 経由で request_id / chain / latency / usage を `logs/llm_context_analyzer.log` に jsonl で記録（なければ従来call）。LLM全体のusageは `logs/llm_usage.jsonl`（router）で集計でき、`scripts/llm_usage_report.py` で要約可能。
- LLMログ統合レポート: `scripts/llm_logs_combined_report.py` で `llm_usage.jsonl` / `llm_context_analyzer.log` / `tts_llm_usage.log` をまとめて要約（件数・モデル/プロバイダ内訳・レイテンシ・トークン合計・last request_id）。監視/定期集計に利用可。
- CIアーティファクト: `llm_smoke` ワークフローが実行後に LLM系ログ (`llm_usage.jsonl`, `llm_context_analyzer.log`, `tts_llm_usage.log`) をアーティファクトとして保存する（存在する場合のみ、best-effort）。
- CapCutドラフト生成チェックリスト（簡易）:
  1) `.env` が正しく読み込まれているか `python scripts/check_env.py` または `commentary_02_srt2images_timeline/check_gemini_key.py` で確認。`.venv/lib/python3.x/site-packages/factory_commentary_env.pth` により cwd を問わず sitecustomize が走る。
  2) `progress/channels/CHxx.csv` に台本パス/企画意図/タグが入っていることを確認し、テンプレ選択は `config/channel_presets.json` + `config/template_registry.json` に存在するものを使う（CH06ダークは `watercolor_gold_blue_ch06_dark.txt`、CH01は 220 ロジック生存で base_period=12s 固定）。
  3) `python commentary_02_srt2images_timeline/tools/auto_capcut_run.py ...` を実行。`--resume` で再利用、`--belt-mode existing` で既存ベルトを尊重する。`logs/auto_run_info.json` を必ず確認。
  4) 生成物確認: `image_cues.json` の `llm_context` に企画意図・タグが入っているか、CapCut draft が `opening_offset` 付きでシフトされているか、画像/字幕の件数がSRT行数と一致しているか。
  5) 画像生成は `llm_context_analyzer` で得たセクション文脈＋テンプレ＋タグをそのまま Gemini image に渡すため、企画CSVを最新化しないと文脈が外れる。ズレを見つけたら CSV→planning_store.refresh→再実行で揃える。
  6) テンプレ管理: `templates/` はチャンネル既定のみ残し、手動スコープの旧テンプレは廃止済み。残存テンプレは `jinsei_warm_gold_blue_strict.txt` (CH01), `watercolor_gold_blue_ch02.txt` (CH02), `senior_health_reading.txt` (CH03), `watercolor_gold_blue_strict.txt` (CH04/07/08/11), `senior_romance_sensual.txt` (CH05), `philosophy_calm_watercolor_oil.txt` (CH09/10), `watercolor_gold_blue_ch06_dark.txt` と `dark_library_calm_curiosity.txt` (CH06)。`template_registry.json` からも manual スコープを削除し、古いシェルは CH 既定テンプレに差し替え済み。

### CH01 固有（220ロジック・きめ細かいカット）
- 分割ロジック: `src/srt2images/cue_maker.py` で CH01 のみ `base_seconds=12` を強制。LLM文脈分割を優先し、秒数固定のフォールバックは補助扱い。
- CapCut: 開始オフセットは preset の `opening_offset`（通常 3.0s）。テンプレは `jinsei_warm_gold_blue_strict.txt` を channel scope から自動選択。
- 画像生成: セクション文脈＋企画CSVタグを Gemini に渡す。`image_cues.json` の `llm_context` に企画の要約が入っていることを確認。
- コマンド例: `python commentary_02_srt2images_timeline/tools/auto_capcut_run.py --channel CH01 --srt input/CH01_人生の道標/220.srt --out output/jinsei220 --draft-root "$HOME/Movies/CapCut/User Data/Projects/com.lveditor.draft" --nanobanana direct --crossfade 0.5 --imgdur 20 --fps 30 --belt-mode llm`

### 企画CSVの参照・UI
- `configs/sources.yaml` に CH01〜CH11 全ての planning CSV と persona を登録済み。script/image/音声パイプラインは常に最新 CSV を参照（`script_pipeline/runner.py` の `planning_csv` ロード）。
- UI `/progress` で `progress/channels/CHxx.csv` を直接表示して確認できる。企画が変わったら CSV を更新→必要なら `planning_store.refresh(force=True)`→再実行。
- 企画→台本への伝播を担保したいときは、CSV更新後に当該話数のステータスをリセットするか、再生成ジョブを実行してメタデータを取り込み直す。

### 環境変数の恒久ロード
- `.env` はリポジトリ直下に一本化。`sitecustomize.py` で Python 起動時に自動読込、`LLMRouter` も `.env` を強制ロード、Gemini Image アダプタも `.env` を探して `GEMINI_API_KEY` を注入。
- FastAPI バックエンドは起動時にリポジトリ直下 `.env` を必ず読むように追加済み。`scripts/with_ytm_env.sh` を使えばシェルでも漏れなく export される。

### リテイク（台本/音声）運用
- デフォルトは `redo_script=true` / `redo_audio=true`（人が確定したら false に落とす運用）。
- API:
  - GET `/api/redo?channel=CH02&type=script|audio|all` … リテイク対象のみ抽出。
  - GET `/api/redo/summary?channel=CH02` … チャンネルごとのリテイク件数（script/audio/both）サマリ。
  - PATCH `/api/channels/{channel}/videos/{video}/redo` … フラグとメモを更新（redo_note）。
- UI: 企画CSVページでリテイクバッジ表示、フィルタ「リテイクのみ」、詳細モーダルで台本/音声リテイクON/OFFとメモを編集＆保存。
- CLI: `scripts/list_redo.py` でリストアップ、`scripts/mark_redo_done.py` で一括クリア（`--channel CH02 --videos 019 020` など）。
- シェル: `scripts/mark_redo_done.sh CH02 019 020 --type audio` などで手早くクリア（`--all` で全件）。
- ジョブ運用: `GET /api/redo` あるいは `scripts/list_redo.py` で対象抽出→再処理→成功時にフラグを false へ（`mark_redo_done.py` でクリア）。未設定は自動で true と見なす。

### 2025-12-12 追加メモ（環境・CapCut・テンプレ・画像文脈）
- `.env` 一本化の恒久策:  
  - Python は `sitecustomize.py` と `LLMRouter` が `.env` を強制ロード（override=True）するため、どの CWD でも `GEMINI_API_KEY` などが拾われる。  
  - FastAPI（ui/backend）も起動時に `.env` を必読。  
  - シェル/Node/外部スクリプトは `scripts/with_ytm_env.sh <cmd>` で `.env` を export してから実行すれば取りこぼしなし。  
  - 健全性チェック: `python scripts/check_env.py` で主要キーの有無を確認。  
- CapCutドラフト CH01 220 ロジック確認:  
  - `cue_maker.py` の CH01 分岐で `base_seconds=12`＋LLM文脈分割を継続。細かいカットとアングル変化は 220 ロジックが生存。  
  - 画像生成は `llm_context` に企画CSVの要約・タグを詰めて Gemini に渡す（`planning_store.refresh()` で最新CSVを強制読込）。  
  - SRT は `commentary_02_srt2images_timeline/input/CH01_人生の道標/220.srt` を指定し、`--belt-mode llm` / `--crossfade 0.5` / `--imgdur 20` / `--fps 30` がデフォルトのおすすめ。  
  - 実行後は `output/{run_name}/image_cues.json` の `llm_context` と `auto_run_info.json` を必ず確認。  
- テンプレ整理: `commentary_02_srt2images_timeline/templates` は CH06 用の `dark_library_calm_curiosity.txt` のみ残置（legacy/未使用は削除済み）。`config/template_registry.json` も channel scope ベース、manual scope なし。  
- サムネ・企画CSV UI: `/progress` で CSV をサムネ付きで確認でき、リテイクON/OFFとメモをモーダルから編集可能（デフォルト true）。タイルはチャンネルアイコンで切替可、モーダルの閉じるボタンは明色で視認性を確保。  
- 最終音声の入力ガード: TTS は human版があれば優先し、`input_path` が assembled 以外の場合は拒否して異常生成を防止。成功時は `redo_audio` を自動クリア。

### VOICEVOX公式ユーザー辞書同期（正規ルート）
- VOICEVOXエンジンの公式ユーザー辞書API（`voicevox_engine` README準拠）を利用できるようにしてある。
  - 参照: `GET /user_dict`
  - 追加: `POST /user_dict_word?surface=...&pronunciation=...&accent_type=...`
  - 更新: `PUT /user_dict_word/{word_uuid}?surface=...&pronunciation=...&accent_type=...`
  - 削除: `DELETE /user_dict_word/{word_uuid}`
- 実装:
  - クライアント: `audio_tts_v2/tts/voicevox_user_dict.py`
  - 同期スクリプト: `audio_tts_v2/scripts/sync_voicevox_user_dict.py`
- 使い方（例）:
  - `PYTHONPATH="$PWD" python3 audio_tts_v2/scripts/sync_voicevox_user_dict.py --channel CH05`
  - 全チャンネル同期: `... --all`
  - 既存surfaceを更新したいとき: `... --overwrite`
  - 変更せず内容確認だけ: `... --dry-run`
- accent_type は公式API必須。repo辞書側に無い場合は、同スクリプトが `audio_query` で推定して登録する（チャンネルの `voice_config.json` の speaker_id を優先）。

### 読み辞書の“正”と使い分け（確定ルール）
- **正本（canonical）は repo 内辞書。VOICEVOX公式辞書は派生物。**
  - チャンネル別辞書: `audio_tts_v2/data/reading_dict/CHxx.yaml`
    - 全動画で再現性を担保するための唯一のソース。
    - 同じsurfaceが複数動画で再発したらここに昇格。
  - 全体共通の安定置換: `audio_tts_v2/configs/learning_dict.json`
    - ほぼ全チャンネルで読みが固定できる語の「前処理置換」層。
  - 動画単位の例外: `local_token_overrides.json`
    - 文脈依存/単発の誤読だけを潰す一時層。再発したらCH辞書へ昇格。
- VOICEVOX公式ユーザー辞書:
  - ローカルでの手動TTSやエディタ利用の安定化のための“キャッシュ層”。
  - 原則は `sync_voicevox_user_dict.py` で repo 辞書から同期して作る。
  - 公式辞書を手で直した場合は **必ず repo 側にも同じ修正を入れる**（正が逆転しないように）。
