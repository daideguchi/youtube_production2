# TTS向けLLMコスト削減と品質確保ガイド

## Aテキストのセクション区切り
- Aテキストは作成段階で `---` の水平線でセクションを明示し、見出しとセットで配置する。
- 水平線を基準に機械的なブロック分割を行うことで、LLMへ渡す最小単位が安定し、過剰なコンテキスト送信を防ぐ。
- 章構成が変わっても `---` が境界として機能するため、分割ロジックやポーズ挿入がシンプルになり、誤読対策の再現性が高まる。

### 現行フローのどこに組み込むか（具体指示）
- **前処理（Markdown剥がし直後）で水平線を注入する**: セクション見出しが決まった段階で `---` を埋め込む。後段の形態素解析・ポーズ生成は水平線をブロック境界としてそのまま利用する。
- **チャンク分割は水平線優先＋見出し維持で固定**: `---` を最優先の境界にし、見出しと本文を同一チャンクにまとめる。これを標準チャンク化ルールとしてLLM送信用の最小単位にする。
- **危険判定はチャンク単位で開始する**: 既存の「MeCabドラフト vs Voicevox かな一致チェック」は、水平線で分けたチャンクを単位として実施し、一致チャンクはLLMをスキップする。
- **LLM監査はチャンクごとの固定テンプレートで送信**: チャンク本文＋危険語ヒント＋規則IDだけを送る（テンプレートは後述の固定フォーマットを流用）。章全体や隣接セクションは送らない。
- **監査結果キャッシュのキーにチャンクハッシュを入れる**: `chunk_hash(original_text + dict_version)` をキーにし、水平線再配置や辞書更新以外でキャッシュを無効化しない。

## トークンコストを下げつつ品質を維持するための施策
### 1. 事前分割と選択的送信
- `---` 区切りや見出し単位でAテキストを先にチャンク化し、危険語/外来語/数字混在のチャンクのみLLMに渡す。
- MeCabやSudachiでの標準読みとVoicevoxかなの一致確認を早段に行い、一致したチャンクはLLMをスキップ。
- **基準例**: 「10%増」「15kg」など数字＋単位の連続は必ず監査対象にする一方、「これはいい。」のような純ひらがな＋終止表現は常にスキップする。
- 警告チャンクはさらに品詞・単位パターンでフィルタリングし、「要LLM監査」ラベルを最小限にする。

### 2. プロンプトの薄型化
- システムプロンプトは共通の安全規約＋短い手順だけにし、ドメイン固有の注釈はYAML化して外部参照（テンプレートID＋差分のみ送信）。
- 例示は最小限のペア（before/after 2〜3件）に固定し、長文化した例はハッシュ化してキャッシュから復元。
- 数値や記号の読み上げ方針は「規則テーブル（例: 半角数字→漢数字不可、助数詞付きは原文）」として先送りし、プロンプトに都度列挙しない。
- **禁止具体例**: 「数字はこう読んで、単位はこう読んで…」と箇条書きで長々送るのをやめ、`reading_rules=v3` のIDだけ渡し、モデル側で紐づくテーブルを参照させる。

### 3. キャッシュと再利用
- セクションID＋ハッシュ（文章＋辞書バージョン）で監査結果をキャッシュし、再生成時は一致チャンクをそのまま流用。
- 危険語YAMLの更新時のみ「影響チャンクだけ再監査」する差分運用にし、全体再処理を避ける。

### 4. モデル粒度の切替
- 一致率の高いチャンクは軽量モデル（例: small instruct系）で監査し、不一致や外来語が多いチャンクだけ高性能モデルにフォールバック。
- フォールバック回数をログ化し、一定割合を超えたら辞書/分割ロジックの改善に投資するサイクルを回す。

### 5. 前処理の揺れ取り
- 句読点・記号の表記揺れを形態素解析前に正規化し、同一チャンクのハッシュ変化を防ぐ。
- 「GPT→ジーピーティー」のような確定置換は前処理で実行し、LLMに推測させない。

### 6. コンテキスト設計
- LLMへ渡す入力は「チャンク本文＋読み規則ID＋危険語ヒント」の3点に限定し、全体構成説明を省く。
- 章間の参照が必要な場合だけ、直前章の要約（50〜80字）を付加し、全文の再送を避ける。
- **送信テンプレート例**: `{chunk_text}\ncontext_hint: <前章80字要約 or none>\nreading_rules: v3\nhazard_terms: ["ボラタイル", "32bit"]` の固定フォーマットにし、フィールド追加を禁止する。

## Sudachi併用のヒント
- Voicevoxとの一致率向上や複合名詞の境界認識を目的に、MeCab結果とSudachi結果を比較し、差分が大きいチャンクだけLLMへ送る二段階フローが有効。
- Sudachiの`reading_form`は長音・促音が整うため、トリビアル差分の判定基準を単純化でき、LLM呼び出しのさらなる削減に繋がる。
- Sudachi用のユーザー辞書は頻出チャンネルから優先的にコンパイルし、効果を測定してから全体適用する。

## 具体的な改修指示（コードの場所と変更内容）
**「どのファイルのどの関数をどう変えるか」を固定する。抽象案ではなく、実装者がそのまま手を入れられる形にする。**

1) **Aテキストへ`---`を強制注入し、ブロック境界として保持する**
- **ファイル/関数**: `audio_tts_v2/tts/preprocess.py::preprocess_a_text`
- **変更**: `strip_markdown`後の`cleaned`に対し、行頭`#`（見出し）または空行の直前に`"---\n"`を挿入するオプション`inject_sections: bool`を追加。`meta["section_markers"]`に挿入後のオフセットを記録する。デフォルトは`True`で`run_tts_pipeline`から必ず有効化。

2) **水平線をSRT分割の第一優先境界にする**
- **ファイル/関数**: `audio_tts_v2/tts/orchestrator.py::_presplit_headings`および`_raw_sentence_blocks_for_srt`
- **変更**:
  - `_presplit_headings`で`---`行を検出したら、改行だけでなくプレースホルダ`"<SECTION>"`行を挿入し、そのまま次工程へ渡す。
  - `_raw_sentence_blocks_for_srt`で`<SECTION>`行に遭遇したら即`_flush`し、新規ブロックを作らず`section_boundary=True`を次ブロックに付与。`raw_text`/`text`には残さない。これにより`run_tts_pipeline`内のステップ1〜3が`---`境界を尊重する。

3) **見出し＋本文を同一チャンクに固定する**
- **ファイル/関数**: `audio_tts_v2/tts/orchestrator.py::_merge_short_blocks`
- **変更**: `heading_prefixes = ("#",)` の判定に加え、直前ブロックが見出しまたは`section_boundary`の場合は結合禁止フラグを立てる。これで見出しと直後の本文が1チャンクに収まり、LLM監査の最小単位が固定される。

4) **チャンク単位のハッシュを生成してLLM送信をキャッシュ可能にする**
- **ファイル/関数**: `audio_tts_v2/tts/orchestrator.py::run_tts_pipeline`（Twin-Engine直後〜`audit_blocks`直前）
- **変更**: 各`srt_blocks[i]`に `chunk_hash = sha1(raw_text + voicevox_kana + mecab_kana + dict_version)` を追加。`dict_version`は`audio_tts_v2/configs/learning_dict.json`とチャンネル辞書の更新時刻でよい。このハッシュを`audit_blocks`へ渡し、同一ハッシュの監査結果は再送しない。

5) **LLM監査をハッシュキーでスキップ**
- **ファイル/関数**: `audio_tts_v2/tts/auditor.py::_select_candidates` と `audit_blocks`
- **変更**: `blocks`引数から`chunk_hash`を受け取り、`cache_dir = Path("logs/tts_audit_cache")`で`{chunk_hash}.json`を参照。存在すれば`b["audit_needed"] = False`にし、結果をブロックへ反映。新規監査時はLMMレスポンスを同名ファイルへ書き出し、辞書更新時のみ削除する。

6) **辞書学習の粒度をフレーズ優先にする実装位置を明記**
- **ファイル/関数**: `audio_tts_v2/tts/auditor.py::_build_vocab_requests`
- **変更**: `grouped[surface]`キーを`surface`単体ではなく`surface + "|" + "".join(span.reasons)`に変更し、同表記異文脈を別グループ化する。`examples`に前後2文を必ず入れてLLMへ送る。戻り値をフレーズ辞書(YAML)へマップする補助スクリプトは`scripts/reading_dict/`配下に追加する（ファイル新設可）。

7) **数字＋単位の必監査をコードで固定**
- **ファイル/関数**: `audio_tts_v2/tts/risk_utils.py::collect_risky_candidates`
- **変更**: `risk_score`算出時に `if token.surface.isdigit() and next_token.surface in {"%", "kg", "倍", "件"}: risk_score = 1.0` を挿入し、`reason="num_unit"`を付与。これを`auditor.py`の`_build_vocab_requests`で最優先`reasons`としてLLMへ渡す（テンプレ不要）。

## 辞書設計を「単語リスト」から進化させるための指針
単語だけの素朴なエントリでは文脈による読み分けを失いやすい。以下のような構造化と運用で、LLM依存を減らしつつ精度を底上げする。

### 1. フレーズ・文脈指向のエントリ
- **複合語・連接形で登録**: 「重複（ちょうふく）」と「重複削除（じゅうふくさくじょ）」のように、出現パターンごとにフレーズ単位で読みを固定する。
- **コンテキスト条件**: 品詞列や周辺語（例: 前が数詞/単位、後ろが助詞「で」など）を条件にして読みを切り替える。YAMLに正規表現または`pos_pattern`/`left_context`/`right_context`キーを持たせる。
- **占位子付きテンプレート**: 「〇〇版」「〇〇系」「〇〇機」はスロットを持つテンプレートで登録し、スロット部分の読みは形態素解析の結果を継承する。
- **具体的な分岐記述**: 「行為」は「悪行」など名詞連接なら「こうい」、動詞「行う」の連用形が直前なら「ぎょうい」と強制する、といったif/elseを辞書で明文化する。

### 2. 形態素属性に基づくルール
- **品詞・活用型を明示**: エントリに`pos`, `conj_type`, `conj_form`を持たせ、活用形のブレを抑える。例: サ変名詞＋「する」連結で「アクセスする→アクセススル」と読む。
- **読みの優先度とフェイルオーバー**: `priority`を付け、上位ルールが不成立なら下位の一般則（例: カタカナ長音付与）に落とす。
- **数値・単位の併記**: 「32bit」「10倍」は数字＋単位を1トークンとして読むルールを用意し、単純分割による誤読を防ぐ。
- **名詞複合の固定**: `pos_pattern: [名詞-固有名詞, 名詞-サ変接続]` のように2語連接を鍵にして「生成AI」「機械学習」を常に1単位として読む。

### 3. 周辺文脈との照合
- **前後2〜3語のN-gramで確認**: 同表記異読語は周辺N-gram一致で確定し、未一致のみLLMに送る。
- **否定・反復・引用の検知**: 「〜ではない」「『〜』」など構文パターンで読みを変える（例: 引用部は原文維持）。
- **否定時の強制戻し**: 「〜しない」「〜ではない」の直前動詞は原形読みを維持し、促音・長音の追加を抑える（例: 「見ない」は「ミナイ」で確定）。

### 4. 学習サイクルの組み込み
- **監査結果の自動取り込み**: audit_blocksの訂正結果を、チャネル別YAMLだけでなく「フレーズ辞書」「テンプレート辞書」に振り分けるスクリプトを用意する。
- **衝突検知とレビュー**: 同表記で異なる読みが登録される場合は差分レポートを出し、頻度の高い方を自動優先、低頻度は手動レビューへ回す。
- **A/B評価**: 新規辞書を影響範囲のチャンクにだけ適用する`shadow`モードを設け、LLM呼び出し削減率と誤読率の両方を記録する。
- **落とし込み例**: audit結果で「校了→コウリョウ」「校了に入る→コウリョウニハイル」が得られたら、前者を単語辞書ではなくテンプレート辞書`<base>に入る`に統合し、単語・フレーズの重複登録を避ける。

### 5. 辞書実装上のTips
- **粒度別ファイル分割**: 固有名詞、外来語、数値・単位、テンプレート、危険語などでYAMLを分割し、コンパイル時にマージする。
- **エンジン差分の吸収層**: MeCab/Sudachi双方に対応するため、内部表現は`surface`, `base`, `reading`に加え、`pos_detail`や`dictionary_form`を持たせ、どちらの出力でも照合できるキーを用意する。
- **キャッシュキーへの辞書版管理**: セクションハッシュに辞書のバージョンIDを含め、辞書更新時だけ影響チャンクを再監査する。
- **例外辞書の優先順位**: 「既知の誤読を強制修正する辞書」を最上位に置き、ユーザー辞書 → テンプレート辞書 → 汎用ルールの順に適用。コンフリクト時はログに残し、頻度とフォールバック回数で自動解決。

## 運用チェックリスト
- [ ] Aテキストに全セクションの境界として `---` を挿入済みか。
- [ ] 危険語・外来語が含まれるチャンクだけLLMへ送るフィルタが効いているか。
- [ ] 監査結果キャッシュのヒット率をモニタリングしているか。
- [ ] 軽量モデル→高性能モデルへのフォールバック頻度が閾値内か。
- [ ] 辞書更新後に影響チャンクのみ再監査できているか。
- [ ] チャンクハッシュ（原文＋辞書バージョン）をキャッシュキーに含め、レイアウト変更以外で無効化していないか。
