# Optional task overrides for LLMRouter
# ここで task ごとに tier/models/options/system_prompt を上書きできる。
# 未設定の場合は llm_router.yaml の定義を使用する。
tasks:
  # NOTE:
  # Azure is optional. In this repo, AZURE_OPENAI_API_KEY may be intentionally disabled
  # (e.g. set to a non-ASCII placeholder), which makes Azure calls fail at the HTTP layer.
  # Prefer the default tier routing (OpenRouter) unless you explicitly want to force Azure.
  #
  # If you want to force Azure for a task, add:
  #   models: [azure_gpt5_mini]
  # BUT only when AZURE_OPENAI_API_KEY is a valid ASCII key.
  visual_bible:
    tier: heavy_reasoning
    options:
      temperature: 0.2
      response_format: json_object

  # A-text quality gate (script_validation): reasoning Judge + Fixer
  script_a_text_quality_judge:
    tier: heavy_reasoning
    models:
      - or_deepseek_r1_distill_qwen_32b
      - or_deepseek_r1_0528
      - or_deepseek_r1
      - or_deepseek_v3_2_exp
    options:
      temperature: 0.2
      response_format: json_object

  script_a_text_quality_fix:
    tier: heavy_reasoning
    models:
      - or_deepseek_r1_distill_qwen_32b
      - or_deepseek_v3_2_exp
      - or_deepseek_r1_0528
      - or_deepseek_r1
    options:
      temperature: 0.4
      max_tokens: 16384

  # A-text hard rescue: extend-only (length shortage)
  script_a_text_quality_extend:
    tier: heavy_reasoning
    models:
      - or_o3_mini
      - or_deepseek_r1_0528
      - or_deepseek_v3_2_exp
    options:
      temperature: 0.2
      response_format: json_object
      max_tokens: 1800

  # A-text rebuild (plan -> draft): last-resort for non-converging scripts
  script_a_text_rebuild_plan:
    tier: heavy_reasoning
    models:
      - or_o3_mini
      - or_deepseek_r1_0528
      - or_deepseek_v3_2_exp
    options:
      temperature: 0.2
      response_format: json_object
      max_tokens: 1800

  script_a_text_rebuild_draft:
    tier: heavy_reasoning
    models:
      - or_deepseek_v3_2_exp
      - or_deepseek_r1_0528
      - or_o3_mini
    options:
      temperature: 0.25
      max_tokens: 16384

  # 例: ここでは gpt-5-mini のみ利用する前提で models を固定
  # script_outline:
  #   models: [gpt-5-mini]
  #   system_prompt_override: "You are a careful editor."
  #   options:
  #     temperature: 0.2
  #     response_format: json_object
