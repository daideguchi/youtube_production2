#!/usr/bin/env python3
"""
å®Œå…¨ãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½ - srt2images-timeline åŒ…æ‹¬çš„å“è³ªç¢ºèªã‚·ã‚¹ãƒ†ãƒ 
ç”¨é€”: ç”Ÿæˆã•ã‚ŒãŸç”»åƒã€CapCutãƒ‰ãƒ©ãƒ•ãƒˆã€SRTæŒ¿å…¥ã®å…¨é …ç›®ã‚’å¾¹åº•æ¤œè¨¼

ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚: ã€Œã“ã‚Œã‚‰ãŒçµ¶å¯¾ã«å®ˆã‚‰ã‚Œã‚‹ã‚ˆã†ã«ãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½ã‚’å¾¹åº•æ•´å‚™ã—ã¦ã€
"""

import os
import sys
import json
import argparse
from pathlib import Path
from typing import Dict, List, Tuple, Any
from PIL import Image
import re

# CapCut API path
_CANDIDATE_API_PATHS = []
env_api_root = os.getenv("CAPCUT_API_ROOT")
if env_api_root:
    _CANDIDATE_API_PATHS.append(Path(env_api_root).expanduser())
_CANDIDATE_API_PATHS.extend([
    Path.home() / "capcut_api",
    Path(__file__).resolve().parents[2] / "50_tools" / "50_1_capcut_api",
])
for _candidate in _CANDIDATE_API_PATHS:
    if _candidate.exists():
        path_str = str(_candidate)
        if path_str not in sys.path:
            sys.path.insert(0, path_str)

try:
    import pyJianYingDraft as draft
    CAPCUT_AVAILABLE = True
except ImportError:
    CAPCUT_AVAILABLE = False
    print("âš ï¸ Warning: pyJianYingDraft not available - CapCut validation will be skipped")


class ComprehensiveValidator:
    """åŒ…æ‹¬çš„å“è³ªæ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.errors = []
        self.warnings = []
        self.info = []
        self.validation_results = {}
    
    def log_error(self, message: str):
        """ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¨˜éŒ²"""
        self.errors.append(message)
        print(f"âŒ ERROR: {message}")
    
    def log_warning(self, message: str):
        """è­¦å‘Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¨˜éŒ²"""
        self.warnings.append(message)
        print(f"âš ï¸ WARNING: {message}")
    
    def log_info(self, message: str):
        """æƒ…å ±ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¨˜éŒ²"""
        self.info.append(message)
        print(f"â„¹ï¸ INFO: {message}")
    
    def validate_image_aspect_ratio(self, images_dir: Path) -> Dict[str, Any]:
        """16:9ç”»åƒæ¯”ç‡ã®å¾¹åº•ç¢ºèª"""
        print("\n=== ğŸ–¼ï¸ ç”»åƒã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”æ¤œè¨¼ ===")
        
        image_files = list(images_dir.glob("*.png"))
        if not image_files:
            self.log_error(f"ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {images_dir}")
            return {"success": False, "total": 0, "valid": 0, "invalid": 0}
        
        target_ratio = 16 / 9  # 1.777...
        target_size = (1920, 1080)
        tolerance = 0.01  # 1%ã®è¨±å®¹èª¤å·®
        
        valid_images = 0
        invalid_images = []
        
        for img_path in sorted(image_files):
            try:
                img = Image.open(img_path)
                current_ratio = img.size[0] / img.size[1]
                ratio_diff = abs(current_ratio - target_ratio)
                
                if ratio_diff <= tolerance and img.size == target_size:
                    valid_images += 1
                    self.log_info(f"âœ… {img_path.name}: {img.size} (ratio: {current_ratio:.3f})")
                else:
                    invalid_images.append({
                        "file": img_path.name,
                        "size": img.size,
                        "ratio": current_ratio,
                        "expected_size": target_size,
                        "expected_ratio": target_ratio
                    })
                    self.log_error(f"ğŸš« {img_path.name}: {img.size} (ratio: {current_ratio:.3f}) - Expected: {target_size} (ratio: {target_ratio:.3f})")
                    
            except Exception as e:
                self.log_error(f"ç”»åƒèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ {img_path.name}: {e}")
                invalid_images.append({"file": img_path.name, "error": str(e)})
        
        success_rate = valid_images / len(image_files) if image_files else 0
        
        result = {
            "success": success_rate == 1.0,
            "total": len(image_files),
            "valid": valid_images,
            "invalid": len(invalid_images),
            "success_rate": success_rate,
            "invalid_details": invalid_images
        }
        
        if success_rate == 1.0:
            self.log_info(f"âœ… å…¨ç”»åƒãŒ16:9 (1920x1080)ã‚’æº€ãŸã—ã¦ã„ã¾ã™: {valid_images}/{len(image_files)}")
        else:
            self.log_error(f"ğŸš« {len(invalid_images)}å€‹ã®ç”»åƒãŒ16:9è¦ä»¶ã‚’æº€ãŸã—ã¦ã„ã¾ã›ã‚“")
        
        return result
    
    def validate_srt_layer_insertion(self, draft_dir: Path, srt_file: Path) -> Dict[str, Any]:
        """SRTãƒ¬ã‚¤ãƒ¤ãƒ¼æŒ¿å…¥ã®å¾¹åº•ç¢ºèª"""
        print("\n=== ğŸ“ SRTãƒ¬ã‚¤ãƒ¤ãƒ¼æŒ¿å…¥æ¤œè¨¼ ===")
        
        if not CAPCUT_AVAILABLE:
            self.log_warning("CapCut APIåˆ©ç”¨ä¸å¯ - SRTãƒ¬ã‚¤ãƒ¤ãƒ¼æ¤œè¨¼ã‚’ã‚¹ã‚­ãƒƒãƒ—")
            return {"success": False, "reason": "CapCut API unavailable"}
        
        if not draft_dir.exists():
            self.log_error(f"CapCutãƒ‰ãƒ©ãƒ•ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {draft_dir}")
            return {"success": False, "reason": "Draft directory not found"}
        
        # SRTãƒ•ã‚¡ã‚¤ãƒ«è§£æ
        srt_subtitles = self._parse_srt_file(srt_file) if srt_file.exists() else []
        expected_subtitle_count = len(srt_subtitles)
        
        try:
            # CapCutãƒ‰ãƒ©ãƒ•ãƒˆèª­ã¿è¾¼ã¿ï¼ˆæ–°APIå¯¾å¿œï¼‰
            try:
                script = draft.Script_file(draft_dir / "draft_content.json", height=1080)
            except TypeError:
                # Fallback for older API
                script = draft.Script_file(draft_dir / "draft_content.json")
            
            # ãƒ†ã‚­ã‚¹ãƒˆãƒˆãƒ©ãƒƒã‚¯ç¢ºèª
            text_tracks = []
            subtitle_segments = []
            
            for track_name, track in script.tracks.items():
                if hasattr(track, 'type') and track.type == 'text':
                    text_tracks.append(track_name)
                    # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°ã‚«ã‚¦ãƒ³ãƒˆ
                    if hasattr(track, 'segments'):
                        subtitle_segments.extend(track.segments)
            
            actual_subtitle_count = len(subtitle_segments)
            
            result = {
                "success": len(text_tracks) > 0 and actual_subtitle_count > 0,
                "expected_subtitles": expected_subtitle_count,
                "actual_subtitles": actual_subtitle_count,
                "text_tracks": text_tracks,
                "has_srt_track": any("srt" in track.lower() for track in text_tracks)
            }
            
            if result["success"]:
                self.log_info(f"âœ… SRTãƒ¬ã‚¤ãƒ¤ãƒ¼æŒ¿å…¥ç¢ºèª: {len(text_tracks)}å€‹ã®ãƒ†ã‚­ã‚¹ãƒˆãƒˆãƒ©ãƒƒã‚¯, {actual_subtitle_count}å€‹ã®å­—å¹•ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ")
                if expected_subtitle_count > 0:
                    match_rate = actual_subtitle_count / expected_subtitle_count
                    if match_rate >= 0.9:  # 90%ä»¥ä¸Šãƒãƒƒãƒ
                        self.log_info(f"âœ… å­—å¹•ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°ãƒãƒƒãƒç‡: {match_rate:.1%}")
                    else:
                        self.log_warning(f"âš ï¸ å­—å¹•ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°ä¸ä¸€è‡´: æœŸå¾…å€¤{expected_subtitle_count}, å®Ÿéš›{actual_subtitle_count}")
            else:
                self.log_error("ğŸš« SRTãƒ¬ã‚¤ãƒ¤ãƒ¼ãŒæ­£ã—ãæŒ¿å…¥ã•ã‚Œã¦ã„ã¾ã›ã‚“")
                
            return result
            
        except Exception as e:
            self.log_error(f"CapCutãƒ‰ãƒ©ãƒ•ãƒˆè§£æã‚¨ãƒ©ãƒ¼: {e}")
            return {"success": False, "reason": f"Draft analysis error: {e}"}
    
    def validate_coordinate_positioning(self, draft_dir: Path, expected_tx: float = -0.163, expected_ty: float = 0.201, expected_scale: float = 0.59) -> Dict[str, Any]:
        """åº§æ¨™ä½ç½®è¨­å®šã®ç¢ºèª"""
        print("\n=== ğŸ“ åº§æ¨™ä½ç½®è¨­å®šæ¤œè¨¼ ===")
        
        if not CAPCUT_AVAILABLE:
            self.log_warning("CapCut APIåˆ©ç”¨ä¸å¯ - åº§æ¨™æ¤œè¨¼ã‚’ã‚¹ã‚­ãƒƒãƒ—")
            return {"success": False, "reason": "CapCut API unavailable"}
        
        try:
            try:
                script = draft.Script_file(draft_dir / "draft_content.json", height=1080)
            except TypeError:
                # Fallback for older API
                script = draft.Script_file(draft_dir / "draft_content.json")
            tolerance = 0.05  # 5%ã®è¨±å®¹èª¤å·®
            
            positioned_segments = 0
            correct_positions = 0
            position_details = []
            
            for track_name, track in script.tracks.items():
                if hasattr(track, 'segments'):
                    for segment in track.segments:
                        if hasattr(segment, 'transform') or hasattr(segment, 'clip_settings'):
                            positioned_segments += 1
                            
                            # åº§æ¨™å–å¾—
                            actual_tx = getattr(segment, 'transform_x', None)
                            actual_ty = getattr(segment, 'transform_y', None)
                            actual_scale = getattr(segment, 'scale', None)
                            
                            if actual_tx is not None and actual_ty is not None and actual_scale is not None:
                                tx_ok = abs(actual_tx - expected_tx) <= tolerance
                                ty_ok = abs(actual_ty - expected_ty) <= tolerance
                                scale_ok = abs(actual_scale - expected_scale) <= tolerance
                                
                                if tx_ok and ty_ok and scale_ok:
                                    correct_positions += 1
                                    self.log_info(f"âœ… æ­£ç¢ºãªåº§æ¨™: TX={actual_tx:.3f}, TY={actual_ty:.3f}, Scale={actual_scale:.3f}")
                                else:
                                    self.log_warning(f"âš ï¸ åº§æ¨™ãšã‚Œ: TX={actual_tx:.3f} (æœŸå¾…{expected_tx:.3f}), TY={actual_ty:.3f} (æœŸå¾…{expected_ty:.3f}), Scale={actual_scale:.3f} (æœŸå¾…{expected_scale:.3f})")
                                
                                position_details.append({
                                    "track": track_name,
                                    "actual": {"tx": actual_tx, "ty": actual_ty, "scale": actual_scale},
                                    "expected": {"tx": expected_tx, "ty": expected_ty, "scale": expected_scale},
                                    "correct": tx_ok and ty_ok and scale_ok
                                })
            
            success_rate = correct_positions / positioned_segments if positioned_segments > 0 else 0
            
            result = {
                "success": success_rate >= 0.8,  # 80%ä»¥ä¸Šæ­£ç¢º
                "positioned_segments": positioned_segments,
                "correct_positions": correct_positions,
                "success_rate": success_rate,
                "details": position_details
            }
            
            if result["success"]:
                self.log_info(f"âœ… åº§æ¨™ä½ç½®ç¢ºèª: {correct_positions}/{positioned_segments}å€‹ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãŒæ­£ç¢ºãªä½ç½®")
            else:
                self.log_error(f"ğŸš« åº§æ¨™ä½ç½®ã‚¨ãƒ©ãƒ¼: {positioned_segments - correct_positions}å€‹ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãŒä¸æ­£ç¢ºãªä½ç½®")
            
            return result
            
        except Exception as e:
            self.log_error(f"åº§æ¨™æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
            return {"success": False, "reason": f"Coordinate validation error: {e}"}
    
    def validate_file_completeness(self, run_dir: Path, srt_file: Path) -> Dict[str, Any]:
        """ãƒ•ã‚¡ã‚¤ãƒ«å®Œæ•´æ€§ã®ç¢ºèª"""
        print("\n=== ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«å®Œæ•´æ€§æ¤œè¨¼ ===")
        
        required_files = [
            "image_cues.json",
            "images/"
        ]
        
        optional_files = [
            "guides/",
            "logs/"
        ]
        
        missing_required = []
        missing_optional = []
        existing_files = []
        
        for req_file in required_files:
            file_path = run_dir / req_file
            if file_path.exists():
                existing_files.append(req_file)
                self.log_info(f"âœ… å¿…é ˆãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨: {req_file}")
            else:
                missing_required.append(req_file)
                self.log_error(f"ğŸš« å¿…é ˆãƒ•ã‚¡ã‚¤ãƒ«ä¸åœ¨: {req_file}")
        
        for opt_file in optional_files:
            file_path = run_dir / opt_file
            if file_path.exists():
                existing_files.append(opt_file)
                self.log_info(f"âœ… ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨: {opt_file}")
            else:
                missing_optional.append(opt_file)
                self.log_info(f"â„¹ï¸ ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ä¸åœ¨: {opt_file}")
        
        # SRTãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
        if srt_file.exists():
            existing_files.append(str(srt_file))
            self.log_info(f"âœ… SRTãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨: {srt_file}")
        else:
            self.log_error(f"ğŸš« SRTãƒ•ã‚¡ã‚¤ãƒ«ä¸åœ¨: {srt_file}")
        
        # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«æ•°ç¢ºèª
        images_dir = run_dir / "images"
        if images_dir.exists():
            image_count = len(list(images_dir.glob("*.png")))
            if image_count > 0:
                self.log_info(f"âœ… ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«æ•°: {image_count}æš")
            else:
                self.log_error("ğŸš« ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        result = {
            "success": len(missing_required) == 0,
            "existing_files": existing_files,
            "missing_required": missing_required,
            "missing_optional": missing_optional,
            "image_count": image_count if 'image_count' in locals() else 0
        }
        
        return result
    
    def _parse_srt_file(self, srt_path: Path) -> List[Dict]:
        """SRTãƒ•ã‚¡ã‚¤ãƒ«è§£æ"""
        if not srt_path.exists():
            return []
        
        content = srt_path.read_text(encoding='utf-8')
        pattern = r'(\d+)\n(\d{2}:\d{2}:\d{2},\d{3}) --> (\d{2}:\d{2}:\d{2},\d{3})\n(.*?)(?=\n\n|\n\d+\n|\Z)'
        matches = re.findall(pattern, content, re.DOTALL)
        
        return [{"index": int(match[0]), "text": match[3].strip()} for match in matches]
    
    def run_comprehensive_validation(self, run_dir: Path, draft_dir: Path = None, srt_file: Path = None) -> Dict[str, Any]:
        """åŒ…æ‹¬çš„å“è³ªæ¤œè¨¼å®Ÿè¡Œ"""
        print("ğŸ” SRT2Images-Timeline åŒ…æ‹¬çš„å“è³ªæ¤œè¨¼é–‹å§‹")
        print(f"ğŸ“‚ æ¤œè¨¼å¯¾è±¡: {run_dir}")
        
        results = {}
        
        # 1. ãƒ•ã‚¡ã‚¤ãƒ«å®Œæ•´æ€§ç¢ºèª
        results["file_completeness"] = self.validate_file_completeness(run_dir, srt_file or Path())
        
        # 2. ç”»åƒã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ç¢ºèª
        images_dir = run_dir / "images"
        results["image_aspect_ratio"] = self.validate_image_aspect_ratio(images_dir)
        
        # 3. SRTãƒ¬ã‚¤ãƒ¤ãƒ¼æŒ¿å…¥ç¢ºèª
        if draft_dir and srt_file:
            results["srt_layer_insertion"] = self.validate_srt_layer_insertion(draft_dir, srt_file)
        
        # 4. åº§æ¨™ä½ç½®ç¢ºèª
        if draft_dir:
            results["coordinate_positioning"] = self.validate_coordinate_positioning(draft_dir)
        
        # ç·åˆåˆ¤å®š
        all_success = all(
            result.get("success", False) 
            for result in results.values() 
            if isinstance(result, dict)
        )
        
        results["overall"] = {
            "success": all_success,
            "error_count": len(self.errors),
            "warning_count": len(self.warnings),
            "info_count": len(self.info)
        }
        
        # æœ€çµ‚çµæœè¡¨ç¤º
        print("\n" + "="*60)
        print("ğŸ ç·åˆæ¤œè¨¼çµæœ")
        print("="*60)
        
        if all_success:
            print("ğŸ‰ âœ… å…¨ã¦ã®æ¤œè¨¼é …ç›®ã‚’ã‚¯ãƒªã‚¢ï¼å“è³ªåŸºæº–ã‚’æº€ãŸã—ã¦ã„ã¾ã™ã€‚")
        else:
            print("âŒ ğŸš« å“è³ªåŸºæº–ã‚’æº€ãŸã—ã¦ã„ãªã„é …ç›®ãŒã‚ã‚Šã¾ã™ã€‚")
        
        print(f"ğŸ“Š ã‚¨ãƒ©ãƒ¼: {len(self.errors)}å€‹, è­¦å‘Š: {len(self.warnings)}å€‹, æƒ…å ±: {len(self.info)}å€‹")
        
        if self.errors:
            print("\nğŸš« ã‚¨ãƒ©ãƒ¼é …ç›®:")
            for error in self.errors:
                print(f"   â€¢ {error}")
        
        if self.warnings:
            print("\nâš ï¸ è­¦å‘Šé …ç›®:")
            for warning in self.warnings:
                print(f"   â€¢ {warning}")
        
        return results


def main():
    parser = argparse.ArgumentParser(
        description="srt2images-timeline åŒ…æ‹¬çš„å“è³ªæ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  # åŸºæœ¬æ¤œè¨¼ï¼ˆç”»åƒã®ã¿ï¼‰
  python3 comprehensive_validation.py --run ./output/auto_20250905_121136
  
  # å®Œå…¨æ¤œè¨¼ï¼ˆCapCut + SRTå«ã‚€ï¼‰
  python3 comprehensive_validation.py \\
    --run ./output/auto_20250905_121136 \\
    --draft-dir "$HOME/Movies/CapCut/User Data/Projects/com.lveditor.draft/001_ã‚·ãƒ‹ã‚¢ã®æœ—èª­_ç”»åƒç‰ˆ" \\
    --srt-file "./path/to/script.srt"
        """
    )
    
    parser.add_argument("--run", required=True, help="srt2imageså‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª")
    parser.add_argument("--draft-dir", help="CapCutãƒ‰ãƒ©ãƒ•ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª")
    parser.add_argument("--srt-file", help="SRTãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹")
    parser.add_argument("--json-output", help="çµæœã‚’JSONã§å‡ºåŠ›ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹")
    
    args = parser.parse_args()
    
    run_dir = Path(args.run).resolve()
    draft_dir = Path(args.draft_dir).resolve() if args.draft_dir else None
    srt_file = Path(args.srt_file).resolve() if args.srt_file else None
    
    if not run_dir.exists():
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: å®Ÿè¡Œãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {run_dir}")
        sys.exit(1)
    
    validator = ComprehensiveValidator()
    results = validator.run_comprehensive_validation(run_dir, draft_dir, srt_file)
    
    # JSONå‡ºåŠ›
    if args.json_output:
        output_path = Path(args.json_output)
        output_path.write_text(json.dumps(results, indent=2, ensure_ascii=False), encoding='utf-8')
        print(f"ğŸ“„ çµæœã‚’JSONã§å‡ºåŠ›: {output_path}")
    
    # çµ‚äº†ã‚³ãƒ¼ãƒ‰è¨­å®š
    sys.exit(0 if results["overall"]["success"] else 1)


if __name__ == "__main__":
    main()
